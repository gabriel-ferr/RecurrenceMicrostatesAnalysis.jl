var documenterSearchIndex = {"docs":
[{"location":"tutorial/gpu/#GPU","page":"GPU","title":"GPU","text":"RecurrenceMicrostatesAnalysis.jl supports GPU acceleration for computing RMA distributions. The GPU backend is implemented using KernelAbstractions.jl, which enables portable GPU execution across different hardware backends.\n\nThe GPU pipeline is implemented via a GPUCore, which defines a single internal kernel used to compute microstate histograms across supported devices.\n\ncompat: Compat\nThe GPU kernel is not compatible with spatial data.","category":"section"},{"location":"tutorial/gpu/#Data-requirements","page":"GPU","title":"Data requirements","text":"The GPU backend supports only Float32 data. Therefore, input datasets must be explicitly converted before being used:\n\nusing RecurrenceMicrostatesAnalysis, Distributions\ndata = StateSpaceSet(Float32.(rand(Uniform(0, 1), 1000)))\n\ndanger: Danger\nWhen using the GPU backend, inputs must be of type Float32. RecurrenceMicrostatesAnalysis.jl is not compatible with Float64 on GPU.","category":"section"},{"location":"tutorial/gpu/#Recurrence-expressions-and-metrics","page":"GPU","title":"Recurrence expressions and metrics","text":"When defining a RecurrenceExpression  for GPU execution, the distance metric must be a subtype of GPUMetric. Metrics from Distances.jl are not supported on GPU.\n\nFor example:\n\nexpr = Standard(0.27f0; metric = GPUEuclidean())\n\ncompat: Compat\nThe GPU backend is not compatible with metrics from Distances.jl.","category":"section"},{"location":"tutorial/gpu/#Moving-data-to-GPU-memory","page":"GPU","title":"Moving data to GPU memory","text":"To enable GPU computation, the data must be transferred to GPU memory. For example:\n\nUsing CUDA:\n\nusing CUDA\ngpu_data = data |> CuVector \n\nUsing Metal:\n\nusing Metal\ngpu_data = data |> MtlVector","category":"section"},{"location":"tutorial/gpu/#Output-handling","page":"GPU","title":"Output handling","text":"Results computed on the GPU are automatically transferred back to the CPU:\n\nhistogram returns a Counts object.\ndistribution returns a Probabilities object.\n\nNo manual data transfer is required for the output.","category":"section"},{"location":"tutorial/gpu/#Metrics-for-GPU","page":"GPU","title":"Metrics for GPU","text":"Since the GPU backend does not support Distances.jl, distance metrics must be implemented explicitly as subtypes of GPUMetric.","category":"section"},{"location":"tutorial/gpu/#Implemented-GPU-metrics","page":"GPU","title":"Implemented GPU metrics","text":"","category":"section"},{"location":"tutorial/gpu/#RecurrenceMicrostatesAnalysis.GPUMetric","page":"GPU","title":"RecurrenceMicrostatesAnalysis.GPUMetric","text":"GPUMetric <: Metric\n\nAbstract supertype for metrics compatible with the GPU backend.\n\nMetrics subtyping GPUMetric must implement the internal evaluation function gpu_evaluate, which is used during GPU-based computations.\n\nImplementations\n\nGPUEuclidean\n\n\n\n\n\n","category":"type"},{"location":"tutorial/gpu/#RecurrenceMicrostatesAnalysis.GPUEuclidean","page":"GPU","title":"RecurrenceMicrostatesAnalysis.GPUEuclidean","text":"GPUEuclidean <: GPUMetric\n\nGPU-compatible implementation of the Euclidean distance metric.\n\nd(vecx vecy) = sqrtsum_i = 1^m (x_i - y_i)^2\n\n\n\n\n\n","category":"type"},{"location":"dev/#RecurrenceMicrostatesAnalysis.jl-for-Devs","page":"Developers","title":"RecurrenceMicrostatesAnalysis.jl for Devs","text":"tip: Tip\nAll pull requests that introduce new functionality must be thoroughly tested and documented. Tests are required only for methods that you extend. We recommend reading the Good Scientific Code Workshop.Always remember to add docstrings to your implementations, as well as tests to validate them.","category":"section"},{"location":"dev/#RecurrenceMicrostatesAnalysis.jl-backend","page":"Developers","title":"RecurrenceMicrostatesAnalysis.jl backend","text":"RecurrenceMicrostatesAnalysis.jl supports multiple backends, depending on the usage context. Each backend is implemented based on an RMACore, which defines how the package computes a histogram.\n\nThere are two main backend implementations:\n\nCPUCore: defines how distributions are computed on the CPU. The default implementation is StandardCPUCore.\nGPUCore: defines how distributions are computed on the GPU. The default implementation is StandardGPUCore.\n\ninfo: Info\nBackend implementations are located in src/core/cpu_core.jl and src/core/gpu/gpu_core.jl. If you plan to implement a new backend, we recommend opening an issue on GitHub beforehand to discuss the design.","category":"section"},{"location":"dev/#Implementing-an-RMACore","page":"Developers","title":"Implementing an RMACore","text":"Although it is possible to implement a custom RMACore directly, we do not recommend doing so. Instead, we strongly suggest implementing either a CPUCore or a GPUCore.\n\nThis approach allows you to reuse utility functions such as get_offsets and get_power_vector, which expect an RMACore as input. Since these functions have different implementations for CPUCore and GPUCore, writing a custom RMACore would require reimplementing them.\n\nTo avoid this, define a new struct that subtypes CPUCore or GPUCore. In this case, the only required method to implement is histogram. For example:\n\nusing Random\nusing ComplexityMeasures\nimport RecurrenceMicrostatesAnalysis as rma\nstruct MyCore{M<:rma.MicrostateShape, S<:rma.SamplingMode} <: rma.CPUCore{M, S}\n    shape::M\n    sampling::S\nend\n\nfunction histogram(\n    core::MyCore,\n    x::rma.StateSpaceSet,\n    y::rma.StateSpaceSet\n)\n    \n    # Construct the sampling space and determine the number of samples\n    space = rma.SamplingSpace(core.shape, x, y)\n    samples = rma.get_num_samples(core.sampling, space)\n\n    # Precompute power vector and offsets\n    pv = rma.get_power_vector(core, core.shape)\n    offsets = rma.get_offsets(core, core.shape)\n\n    # Allocate histogram\n    hist = zeros(Int, rma.get_histogram_size(core.shape))\n\n    # Task-local RNG (ignored for Full sampling)\n    local_rng = TaskLocalRNG()\n\n    # Histogram computation\n    for m in 1:samples\n        #   Get the sample.\n        i, j = rma.get_sample(core, core.sampling, space, local_rng, m)\n        #   Compute the microstate index.\n        idx = rma.compute_motif(core.shape.expr, x, y, i, j, pv, offsets)\n        @inbounds hist[idx] += 1\n    end\n\n    return Counts(hist, eachindex(hist))\nend\n\ninfo: Info\nTo ensure compatibility with the internal API, custom backends must support the keyword argument threads (for CPUCore) or groupsize (for GPUCore), as required by the distribution overloads.\n\ndata = rma.StateSpaceSet(rand(1000))\nhistogram(MyCore(rma.Rect(rma.Standard(0.27), 2), rma.SRandom(0.05)), data, data)\n\nwarning: Warning\nCPU and GPU backends differ significantly in their execution models. In the GPU backend, random samples must be generated before histogram computation. The histogram itself is computed inside the gpu_histogram! kernel.See the StandardGPUCore implementation in src/core/gpu_core.jl for details.\n\ndanger: Danger\nRecurrenceMicrostatesAnalysis.jl provides multiple backends that are only partially compatible.CPU backends do not necessarily support spatial data.\nSpatial analyses require dedicated implementations.\nThe GPU backend is fully incompatible with spatial data.Please consider these limitations carefully when extending or using backend functionality.","category":"section"},{"location":"dev/#Adding-a-New-Recurrence-Function","page":"Developers","title":"Adding a New Recurrence Function","text":"","category":"section"},{"location":"dev/#Steps","page":"Developers","title":"Steps","text":"Define the mathematical expression of your recurrence function. It must return a binary value: 0 for non-recurrence and 1 for recurrence.\nDefine a new type YourType <:RecurrenceExpression. Constant parameters (e.g., thresholds and metric) should be fields of this type.\nImplement the appropriate recurrence dispatch:\nTime series:   recurrence(expr::YourType, x::StateSpaceSet, y::StateSpaceSet, i::Int, j::Int)\nSpatial data:   recurrence(expr::YourType, x::AbstractArray{<:Real}, y::AbstractArray{<:Real}, i::NTuple{N,Int}, j::NTuple{M,Int})\nAdd a docstring describing the mathematical definition and relevant references.\nAdd the recurrence expression to docs/src/tutorial/recurrences.md.\nAdd the expression to the RecurrenceExpression docstring.\nAdd tests to test/distributions.jl under the test set recurrence expressions (with CPUCore).\n\nwarning: Warning\nA recurrence function must always return UInt(0) or UInt(1).\n\ntodo: Todo\nTo support GPU execution, also implement gpu_recurrence(expr::YourType, x, y, i, j, n). See Standard for reference.","category":"section"},{"location":"dev/#Adding-a-New-Sampling-Mode","page":"Developers","title":"Adding a New Sampling Mode","text":"","category":"section"},{"location":"dev/#Steps-2","page":"Developers","title":"Steps","text":"Define how the sampling mode operates: which microstates are sampled, from which regions, and in what quantity. The SamplingSpace must be taken into account when designing the sampling logic.\nDefine a new struct that is a subtype of SamplingMode. The struct may be empty (e.g. Full) or contain parameters such as a sampling rate (e.g. SRandom).\nImplement the dispatch get_num_samples(mode::YourType, space::SamplingSpace) which determines the number of samples to be drawn given the sampling mode and the sampling space. Two sampling space types exist: SSRect2 (time series) and SSRectN (spatial data).\nImplement the dispatch get_sample(core::RMACore, mode::YourType, space::SamplingSpace) which returns the positions to be sampled. Separate implementations may be required for each RMACore and each SamplingSpace. Full coverage is encouraged but not mandatory, provided that the supported cases are clearly documented in the docstring.\nAdd a docstring to your sampling mode describing its behavior and initialization. Follow the style of the existing sampling modes listed in Implemented sampling modes.\nAdd your sampling mode to the list in docs/src/tutorial/shapes_and_sampling.md.\nAdd your type to the list in the SamplingMode docstring.\nAdd tests in test/distributions.jl under the test set sampling mode (CPU backend).\n\nwarning: Warning\nThe get_sample logic differs between CPU and GPU backends. On the CPU, random samples are generated during histogram computation. On the GPU, samples must be generated beforehand, outside the kernel, and the kernel operates only on precomputed values.","category":"section"},{"location":"dev/#Adding-a-new-Microstate-Shape","page":"Developers","title":"Adding a new Microstate Shape","text":"Defining a Microstate Shape is one of the most challenging tasks in this package (except for backend development, which is described by an RMACore).\n\nA microstate shape acts as an intermediate structure between the sampling process and the recurrence function. Given an initial RP position (i j), it determines which additional recurrences must be evaluated and computes them using the recurrence expression. The resulting microstate is then converted into a decimal representation, which is used as an index in the histogram.","category":"section"},{"location":"dev/#Design-considerations","page":"Developers","title":"Design considerations","text":"Before implementing a microstate shape, it is essential to define its structure and reading order. For example, square microstates are typically read row-wise, while triangular microstates may be read column-wise. Each position in the microstate structure must be associated with a power of two in order to convert the binary microstate into a decimal index.\n\nbeginpmatrix\n2^0  2^1  2^2 \n2^3  2^4  2^5 \n2^6  2^7  2^8\nendpmatrix","category":"section"},{"location":"dev/#Implementation-steps","page":"Developers","title":"Implementation steps","text":"Define a new struct that is a subtype of MicrostateShape. The struct must include a field expr, which stores the RecurrenceExpression used to compute recurrences at runtime.\n\nUnlike RecurrenceExpression and SamplingMode, a MicrostateShape does not require the implementation of recurrence or get_sample methods. Microstate computation is handled by the unified compute_motif function for the CPUCore, and by gpu_compute_motif for the GPUCore.\n\nThe only exception is spatial data, for which a custom compute_motif implementation is required. For example:\n\n@inline function compute_motif(\n    shape::RectN,\n    x::AbstractArray{<: Real},\n    y::AbstractArray{<: Real},\n    idx::Vector{Int},\n    itr::Vector{Int},\n    power_vector::SVector{N, Int}\n) where {N}\n    \n    index = 0\n    dim = ndims(x) - 1\n    copy!(itr, idx)\n\n    @inbounds @fastmath for p in power_vector\n\n        i = ntuple(k -> itr[k], dim)\n        j = ntuple(k -> itr[dim + k], length(shape.structure) - dim)\n\n        index += recurrence(shape.expr, x, y, i, j) * p\n\n        itr[1] += 1\n        for k in 1:length(shape.structure) - 1\n            if (itr[k] > idx[k] + (shape.structure[k] - 1))\n                itr[k] = idx[k]\n                itr[k + 1] += 1\n            else\n                break\n            end\n        end\n    end\n\n    return index + 1\nend\n\nAlthough time-series microstate shapes do not require a custom compute_motif implementation, three utility functions must be defined to describe the properties of the shape:\n\nget_histogram_size(shape::YourType)   Returns the length of the histogram, given by 2^sigma, where sigma is the number of recurrences in the microstate structure.\nget_power_vector(core::RMACore, shape::YourType)   Returns the vector of powers of two used to convert the microstate into its decimal representation. This function differs between CPU and GPU backends due to integer size (Int on CPU, Int32 on GPU).\nget_offsets(core::RMACore, shape::YourType)   Returns the offsets relative to the initial position (i j) that define the remaining recurrence positions of the microstate. This function must be consistent with get_power_vector and also differs between CPU and GPU backends.\n\ntip: Tip\nFor improved performance, we strongly recommend using @generated functions when implementing these utilities (except for spatial data).\n\nAdditionally, a SamplingSpace must be defined for the new microstate shape. For time-series data, this is typically SSRect2, while spatial data require SSRectN.\n\nThe sampling space must be initialized using the following constructor:\n\nSamplingSpace(\n    ::MicrostateShape, \n    x::Union{StateSpaceSet, AbstractGPUVector{SVector{N, Float32}}}, \n    y::Union{StateSpaceSet, AbstractGPUVector{SVector{N, Float32}}}\n)\n\nAfter implementation, the following steps are required:\n\nAdd a docstring to your MicrostateShape, explaining its behavior and initialization.\nAdd the definition to the section Implemented microstates shapes in docs/src/tutorial/shapes_and_sampling.md.\nAdd the type to the list in the MicrostateShape docstring.\nAdd tests to test/distributions.jl under the test set motif shapes (with CPUCore).","category":"section"},{"location":"dev/#Example","page":"Developers","title":"Example","text":"First, we define the shape struct.\n\nusing RecurrenceMicrostatesAnalysis\nstruct Line{N, B, E <: RecurrenceExpression} <: MicrostateShape\n    expr::E\nend\n\nLine(expr::E, N; B = 2) where {E} = Line{N, B, E}(expr)\n\nNext, we implements the three utils functions.\n\n@generated function get_histogram_size(::Line{N, B, E}) where {N, B, E}\n    size = B^(N)\n    return :( $size )\nend\n\n@generated function get_power_vector(::CPUCore, ::Line{N, B, E}) where {N, B, E}\n    expr = :(SVector{$N}( $([:(B^$i) for i in 0:(N-1)]... ) ))\n    return expr\nend\n\n@generated function get_offsets(::CPUCore, ::Line{N, B, E}) where {N, B, E}\n    elems = [ :(SVector{2, Int}(0, $h)) for h in 0:(N - 1)]\n    return :( SVector{$N, $(SVector{2, Int})}( $(elems...) ) )\nend\n\nFinally, we define our sampling space: (can be only for time series)\n\nusing GPUArraysCore, StaticArrays\nSamplingSpace(\n    ::Line{N, B, E}, \n    x::Union{StateSpaceSet, AbstractGPUVector{SVector{D, Float32}}}, \n    y::Union{StateSpaceSet, AbstractGPUVector{SVector{D, Float32}}}\n) where {N, B, E<:RecurrenceExpression, D} = RecurrenceMicrostatesAnalysis.SSRect2(length(x), length(y) - N + 1)\n\nAnd done, the shape can be used üòÉ. Remember to document it!\n\nwarning: Warning\nThe backend needs to have access to the util functions, them it is important to do the implementation inside the package module.","category":"section"},{"location":"dev/#Adding-a-New-Quantifier","page":"Developers","title":"Adding a New Quantifier","text":"","category":"section"},{"location":"dev/#Steps-3","page":"Developers","title":"Steps","text":"Define a new quantifier type that is a subtype of QuantificationMeasure.\nImplement the corresponding measure dispatch used to compute the quantifier.\nAdd a docstring to the quantifier type, following the style of existing quantifiers.\nDocument the quantifier in docs/src/tutorial/quantifiers.md, including its definition, mathematical formulation, references, and examples when possible.\nAdd the quantifier to the list in the QuantificationMeasure docstring.\nAdd tests for the quantifier in test/rqa.jl.","category":"section"},{"location":"dev/#Adding-a-New-GPU-Metric","page":"Developers","title":"Adding a New GPU Metric","text":"Since the Distances.jl package is not compatible with GPU execution, metric evaluations must be implemented manually to enable GPU support.","category":"section"},{"location":"dev/#Steps-4","page":"Developers","title":"Steps","text":"Define a new type that is a subtype of GPUMetric.\nImplement the dispatch   gpu_evaluate(::YourMetric, x, y, i, j, n)   where x and y are AbstractGPUVector{SVector{N, Float32}}, i and j are indices, and n is the dimensionality of the vectors.\nAdd a docstring describing the metric, including its mathematical definition and parameters. Include references when applicable.\nDocument the metric in the section Implemented GPU metrics in docs/src/tutorial/gpu.md.\nAdd a reference to the metric in the GPUMetric docstring.\n\ndanger: Danger\nGPU backends in RecurrenceMicrostatesAnalysis.jl operate exclusively with Float32. The use of Float64 is not supported.","category":"section"},{"location":"dev/#RecurrenceMicrostatesAnalysis.RMACore","page":"Developers","title":"RecurrenceMicrostatesAnalysis.RMACore","text":"RMACore\n\nAbstract supertype that defines the execution pipeline of the package.\n\nAn instance of RMACore must be provided to the histogram function to determine how the histogram computation is performed.\n\nConcrete implementations of RMACore are CPUCore and GPUCore, which target CPU and GPU execution, respectively. Implementing custom subtypes of RMACore is strongly discouraged, as doing so requires reimplementing several internal utilities for the package ecosystem to function correctly.\n\nImplementations\n\nCPUCore\nGPUCore\n\n\n\n\n\n","category":"type"},{"location":"dev/#RecurrenceMicrostatesAnalysis.CPUCore","page":"Developers","title":"RecurrenceMicrostatesAnalysis.CPUCore","text":"CPUCore{M<:MicrostateShape, S<:SamplingMode} <: RMACore\n\nAbstract CPU backend that implements the RecurrenceMicrostatesAnalysis.jl execution pipeline on central processing units.\n\nThe package provides a default implementation via StandardCPUCore.\n\nConcrete subtypes of CPUCore must define the following fields:\n\nshape: the MicrostateShape used to construct microstates.\nsampling: the SamplingMode used to sample the recurrence space.\n\nImplementations\n\nStandardCPUCore\n\n\n\n\n\n","category":"type"},{"location":"dev/#RecurrenceMicrostatesAnalysis.GPUCore","page":"Developers","title":"RecurrenceMicrostatesAnalysis.GPUCore","text":"GPUCore{B, M<:MicrostateShape, S<:SamplingMode} <: RMACore\n\nAbstract GPU backend that implements the RecurrenceMicrostatesAnalysis.jl execution pipeline on graphics processing units.\n\nThe package provides a default implementation via StandardGPUCore.\n\nConcrete subtypes of GPUCore must define the following fields:\n\nbackend: the GPU backend device (e.g. CUDABackend, MetalBackend).\nshape: the MicrostateShape used to construct microstates.\nsampling: the SamplingMode used to sample the recurrence space.\n\nImplementations\n\nStandardGPUCore\n\n\n\n\n\n","category":"type"},{"location":"dev/#RecurrenceMicrostatesAnalysis.StandardCPUCore","page":"Developers","title":"RecurrenceMicrostatesAnalysis.StandardCPUCore","text":"StandardCPUCore{M<:MicrostateShape, S<:SamplingMode} <: CPUCore{M, S}\n\nDefault CPU backend implementation for RecurrenceMicrostatesAnalysis.jl.\n\nThis type provides the standard execution pipeline for computing recurrence microstate distributions on CPU devices.\n\nInitialization\n\ncore = CPUCore(shape, sampling)\n\n\n\n\n\n","category":"type"},{"location":"dev/#RecurrenceMicrostatesAnalysis.StandardGPUCore","page":"Developers","title":"RecurrenceMicrostatesAnalysis.StandardGPUCore","text":"StandardGPUCore{B, M<:MicrostateShape, S<:SamplingMode} <: GPUCore{B, M, S}\n\nDefault GPU backend implementation for RecurrenceMicrostatesAnalysis.jl.\n\nThis type provides the standard execution pipeline for computing recurrence microstate distributions on GPU devices.\n\nInitialization\n\ncore = GPUCore(backend, shape, sampling)\n\n\n\n\n\n","category":"type"},{"location":"examples/ml/#RMA-with-Machine-Learning","page":"Machine Learning","title":"RMA with Machine Learning","text":"","category":"section"},{"location":"examples/ml/#Classification-using-Flux.jl","page":"Machine Learning","title":"Classification using Flux.jl","text":"Flux.jl is a user-friendly machine learning library in Julia that provides a wide range of tools for building and training neural networks.\n\nIn this example, we demonstrate how to use Flux.jl together with RecurrenceMicrostatesAnalysis.jl to train a multilayer perceptron (MLP) for classifying a dynamical system, following the approach presented in (Spezzatto et al., 2024).","category":"section"},{"location":"examples/ml/#Importing-required-packages","page":"Machine Learning","title":"Importing required packages","text":"using Flux\nusing DynamicalSystems\nusing RecurrenceMicrostatesAnalysis","category":"section"},{"location":"examples/ml/#Generating-data","page":"Machine Learning","title":"Generating data","text":"We use the Lorenz system as the data source, which can be simulated using DynamicalSystems.jl:\n\nfunction lorenz!(u, p, t)\n    œÉ, œÅ, Œ≤ = p\n    x, y, z = u\n\n    return SVector(\n        œÉ * (y - x),\n        x * (œÅ - z) - y,\n        x * y - Œ≤ * z\n    )\nend\n\nfunction lorenz_trajectory(œÉ, œÅ, Œ≤; u0 = rand(3), t = 400.0, Ttr = 1200.0, Œît_sample = 0.2)\n    p = (œÉ, œÅ, Œ≤)\n    cds =  ContinuousDynamicalSystem(lorenz!, u0, p)\n    x, _ = trajectory(cds, t; Ttr = Ttr, Œît = Œît_sample)\n    return x\nend\n\nWe fix the parameters sigma = 10 and beta = 83, and vary rho in 260 270 280 290 300. The goal is to generate time series for each value of rho and train a classifier to identify which parameter value generated a given trajectory.","category":"section"},{"location":"examples/ml/#Creating-training-and-test-datasets","page":"Machine Learning","title":"Creating training and test datasets","text":"First, we define the classes and the size of the training and test datasets:\n\nœÅ_cls = [26.0, 27.0, 28.0, 29.0, 30.0];\nnum_samples_to_test = 50;\nnum_samples_to_train = 200;\n\nFirst, we define the classes and the size of the training and test datasets:\n\ntrain_timeseries = Vector{StateSpaceSet}(undef, length(œÅ_cls) * num_samples_to_train)\ntest_timeseries = Vector{StateSpaceSet}(undef, length(œÅ_cls) * num_samples_to_test)\n\ntrain_labels = Vector{Float64}(undef, length(œÅ_cls) * num_samples_to_train)\ntest_labels = Vector{Float64}(undef, length(œÅ_cls) * num_samples_to_test)\n\nThe following function generates the data:\n\nfunction generate_data!(labels, data, classes, num_elements_per_class)\n    c = 1\n    for i ‚àà eachindex(labels)\n        labels[i] = classes[c]\n        data[i] = lorenz_trajectory(10.0, classes[c], 8/3)\n\n        if (i % num_elements_per_class == 0)\n            c += 1\n        end\n    end\nend\n\ngenerate_data!(train_labels, train_timeseries, œÅ_cls, num_samples_to_train)\ntrain_timeseries\n\ngenerate_data!(test_labels, test_timeseries, œÅ_cls, num_samples_to_test)\ntest_timeseries","category":"section"},{"location":"examples/ml/#Preparing-the-input-features","page":"Machine Learning","title":"Preparing the input features","text":"For each time series, we compute the RMA distribution and store it as a feature vector.\n\nmicrostate_n = 3\ntrain_dataset = Matrix{Float64}(undef, 2^(microstate_n * microstate_n) + 2, length(train_labels))\ntest_dataset = Matrix{Float64}(undef, 2^(microstate_n * microstate_n) + 2, length(test_labels))\n\nThe following function computes the RMA features:\n\nfunction get_probs!(dataset, timeseries, n)\n    for i ‚àà eachindex(timeseries)\n        th, s = optimize(Threshold(), RecurrenceEntropy(), timeseries[i], n)\n        dist = distribution(timeseries[i], th, n)\n        dataset[1, i] = th\n        dataset[2, i] = s\n        dataset[3:end, i] = dist[1:end]\n    end\nend\n\nget_probs!(train_dataset, train_timeseries, microstate_n)\ntrain_dataset\n\nget_probs!(test_dataset, test_timeseries, microstate_n)\ntest_dataset","category":"section"},{"location":"examples/ml/#Defining-the-neural-network-model","page":"Machine Learning","title":"Defining the neural network model","text":"model = Chain(\n    Dense(2^(microstate_n * microstate_n) + 2 => 512, identity),\n    Dense(512 => 256, selu),\n    Dense(256 => 64, selu),\n    Dense(64 => length(œÅ_cls)),\n    softmax\n)\n\nmodel = f64(model)","category":"section"},{"location":"examples/ml/#Training-the-MLP","page":"Machine Learning","title":"Training the MLP","text":"First, we encode the labels using one-hot vectors:\n\ntrain_labels = Flux.onehotbatch(train_labels, œÅ_cls)\n\ntest_labels = Flux.onehotbatch(test_labels, œÅ_cls) \n\nWe then define the data loader and optimizer:\n\nloader = Flux.DataLoader((train_dataset, train_labels), batchsize = 32, shuffle = true)\n\nopt = Flux.setup(Flux.Adam(0.005), model)\n\nThe training loop is:\n\nfor epc ‚àà 1:50\n    for (x, y) ‚àà loader\n        _, grads = Flux.withgradient(model) do m\n            y_hat = m(x)\n            Flux.crossentropy(y_hat, y)\n        end\n\n        Flux.update!(opt, model, grads[1])\n    end\nend","category":"section"},{"location":"examples/ml/#Model-evaluation","page":"Machine Learning","title":"Model evaluation","text":"We compute the classification accuracy as follows:\n\nusing LinearAlgebra\nfunction get_quatifiers(predict, trusty, classes)\n    conf = zeros(Int, length(classes), length(classes))\n    sz = size(predict, 2)\n\n    for i in 1:sz\n        mx_prd = findmax(predict[:, i])\n        mx_trt = findmax(trusty[:, i])\n\n        conf[mx_prd[2], mx_trt[2]] += 1\n    end\n\n    return tr(conf) / (sum(conf) + eps())\nend\n\naccuracy = get_quatifiers(model(test_dataset), test_labels, œÅ_cls)\naccuracy * 100","category":"section"},{"location":"tutorial/recurrences/#Recurrence-Functions","page":"Recurrence Functions","title":"Recurrence Functions","text":"A recurrence function determines whether two states of a dynamical system, vecx and vecy, are recurrent.\n\nIt is defined by an expression of the form\n\nR(vecx vecy) = Theta(varepsilon - vecx - vecy)\n\nwhere Theta(cdot) denotes the Heaviside step function and varepsilon is the threshold parameter defining the maximum distance between two states for them to be considered varepsilon-recurrent.\n\nThis definition differs from the expression used to construct the full recurrence matrix, introduced in the section A brief review. While the recurrence matrix evaluates all pairwise recurrences in a time series, a recurrence function computes a single recurrence value between two states.\n\nIn RecurrenceMicrostatesAnalysis.jl, recurrence functions are implemented via  the RecurrenceExpression abstraction. The actual recurrence evaluation is performed by implementing the recurrence function for the corresponding expression type.","category":"section"},{"location":"tutorial/recurrences/#Implemented-recurrence-functions","page":"Recurrence Functions","title":"Implemented recurrence functions","text":"","category":"section"},{"location":"tutorial/recurrences/#RecurrenceMicrostatesAnalysis.RecurrenceExpression","page":"Recurrence Functions","title":"RecurrenceMicrostatesAnalysis.RecurrenceExpression","text":"RecurrenceExpression\n\nAbstract supertype for recurrence expressions implemented in the package.\n\nConcrete subtypes of RecurrenceExpression must implement the recurrence function, which defines how recurrence between two states is evaluated.\n\nImplementations\n\nStandard\nCorridor\n\n\n\n\n\n","category":"type"},{"location":"tutorial/recurrences/#RecurrenceMicrostatesAnalysis.recurrence","page":"Recurrence Functions","title":"RecurrenceMicrostatesAnalysis.recurrence","text":"recurrence(expr::RecurrenceExpression, [x], [y], [...])\n\nDefine how the recurrence state between [x] and [y] is computed for a given RecurrenceExpression.\n\nThe additional arguments ([...]) depend on whether the recurrence is computed for time-series or spatial data.\n\nTime-series recurrence\n\nfunction recurrence(expr::RecurrenceExpression, x::StateSpaceSet, y::StateSpaceSet, ::Int, ::Int)\n\nThe two Int arguments correspond to the positions (i j) in the time series used to evaluate recurrence.\n\nSpatial recurrence\n\nfunction recurrence(expr::RecurrenceExpression, x::AbstractArray{<:Real}, y::AbstractArray{<:Real}, ::NTuple{N, Int}, ::NTuple{M, Int})\n\nThe two NTuple{N, Int} arguments correspond to the positions (vec i vec j) in the spatial data used to evaluate recurrence.\n\ninfo: Info\nTo support GPU execution, recurrence expressions must implement gpu_recurrence instead of recurrence.  The arguments are equivalent, with the addition of the phase-space dimension as an input parameter. See Standard for a reference implementation.\n\nOutput\n\nThe recurrence function must always return a UInt8: 0 for non-recurrence and 1 for recurrence.\n\n\n\n\n\n","category":"function"},{"location":"tutorial/recurrences/#RecurrenceMicrostatesAnalysis.Standard","page":"Recurrence Functions","title":"RecurrenceMicrostatesAnalysis.Standard","text":"Standard <: RecurrenceExpression\n\nRecurrence expression defined by the standard threshold criterion:\n\nR(vecx vecy) = Theta(varepsilon - vecx - vecy)\n\nwhere Theta(cdot) denotes the Heaviside function and varepsilon is the distance threshold defining the maximum separation for two states to be considered recurrent.\n\nThe Standard struct stores the threshold parameter Œµ, as well as the distance metric used to evaluate vecx - vecy. The metric must be defined using the Distances.jl package.\n\nConstructor\n\nStandard(Œµ::Real; metric::Metric = Euclidean())\n\nExamples\n\nStandard(0.27)\nStandard(0.27; metric = Cityblock())\n\nThe recurrence evaluation is performed via the recurrence function. For GPU execution, the corresponding implementation is provided by gpu_recurrence.\n\n\n\n\n\n","category":"type"},{"location":"tutorial/recurrences/#RecurrenceMicrostatesAnalysis.Corridor","page":"Recurrence Functions","title":"RecurrenceMicrostatesAnalysis.Corridor","text":"Corridor <: RecurrenceExpression\n\nRecurrence expression defined by the corridor criterion introduced in (Iwanski and Bradley, 1998):\n\nR(vecx vecy) = Theta(vecx - vecy - varepsilon_min) cdot Theta(varepsilon_max - vecx - vecy)\n\nwhere Theta(cdot) denotes the Heaviside function and (varepsilon_min varepsilon_max) define the minimum and maximum distance thresholds for two states to be considered recurrent.\n\nThe Corridor struct stores the corridor thresholds Œµ_min and Œµ_max, as well as the distance metric used to evaluate vecx - vecy. The metric must be defined using the Distances.jl package.\n\nConstructor\n\nCorridor(Œµ_min::Real, Œµ_max::Real; metric::Metric = Euclidean())\n\nExamples\n\nCorridor(0.05, 0.27)\nCorridor(0.05, 0.27; metric = Cityblock())\n\nThe recurrence evaluation is performed via the recurrence function. For GPU execution, the corresponding implementation is provided by gpu_recurrence.\n\n\n\n\n\n","category":"type"},{"location":"tutorial/utils/#Utils","page":"Utils","title":"Utils","text":"This section describes utility functionalities provided by RecurrenceMicrostatesAnalysis.jl, including parameter optimization and operations on recurrence microstates.","category":"section"},{"location":"tutorial/utils/#Optimizing-a-parameter","page":"Utils","title":"Optimizing a parameter","text":"When working with recurrence plots (RPs), a well-known challenge is selecting an appropriate recurrence threshold. Within the RMA framework, this issue is addressed by optimizing an information-theoretic or complexity-based measure with respect to the threshold parameter.\n\nIn practice, it is common to determine the threshold that maximizes either the RecurrenceEntropy or the Disorder quantifier (Lima Prado et al., 2023).\n\nThis optimization procedure is implemented via the optimize function, which computes the optimal value of a given Parameter.","category":"section"},{"location":"tutorial/utils/#Parameters","page":"Utils","title":"Parameters","text":"","category":"section"},{"location":"tutorial/utils/#Operations-on-microstates","page":"Utils","title":"Operations on microstates","text":"The package also provides a set of operations that can be applied to recurrence microstates or to their decimal representations.","category":"section"},{"location":"tutorial/utils/#Permutations-and-Transposition","page":"Utils","title":"Permutations and Transposition","text":"When working with square microstates, it is natural to consider symmetry operations such as row and column permutations, as well as transposition. These operations are particularly important for defining equivalence classes used in the computation of the Disorder quantifier.\n\nTo illustrate these operations, we consider a square microstate of size 3 times 3:\n\nmathbfM = beginpmatrix\na  b  c \nd  e  f \ng  h  i\nendpmatrix\n\ninfo: Info\nThe primary purpose of these operations is to define equivalence classes of microstates used in the computation of Disorder.","category":"section"},{"location":"tutorial/utils/#Permutations-of-Rows","page":"Utils","title":"Permutations of Rows","text":"Let sigma in S_N be a permutation, where S_N is the symmetric group, and let mathcalL_sigma denote the operator that permutes the rows of a microstate mathbfM according to sigma.\n\nFor example, for sigma = 132, the third and second rows are exchanged, while the first row remains unchanged:\n\nmathcalL_132mathbfM = beginpmatrix\na  b  c \ng  h  i \nd  e  f\nendpmatrix\n\nFor a given microstate size n, all possible row (or column) permutations can be generated using the Combinatorics.jl package:\n\nusing Combinatorics\n\nn = 3\nSn = collect(permutations(1:n))\n\nœÉ = Sn[2]\n\nThe permutation is applied using PermuteRows  operation. For example, consider the square 3times 3 microstate with decimal index I = 237:\n\nmathbfM = beginpmatrix\n0  0  1 \n1  0  1 \n1  1  0\nendpmatrix\n\nusing RecurrenceMicrostatesAnalysis\n\nshape = Rect(n, n)\nrow_permutation = PermuteRows(shape)\n\noperate(row_permutation, 237, œÉ)\n\nThe result is the microstate with decimal identifier I = 239, corresponding to:\n\nmathcalL_132mathbfM = beginpmatrix\n0  0  1 \n1  1  0 \n1  0  1\nendpmatrix","category":"section"},{"location":"tutorial/utils/#Permutations-of-Columns","page":"Utils","title":"Permutations of Columns","text":"Column permutations follow the same logic as row permutations, but are applied to the columns of the microstate.\n\nLet mathcalC_sigma denote the operator that permutes the columns of mathbfM according to sigma in S_N. For sigma = 132, the transformation is given by:\n\nmathcalC_132mathbfM = beginpmatrix\na  c  b \nd  f  e \ng  i  h\nendpmatrix\n\nUsing the same example of I = 237, column permutation is performed using the PermuteColumns operation:\n\ncol_permutation = PermuteColumns(shape; S = Sn)\n\noperate(col_permutation, 237, 2)\n\nThe resulting microstate has decimal identifier I = 347, corresponding to:\n\nmathcalC_132mathbfM = beginpmatrix\n0  1  0 \n1  1  0 \n1  0  1\nendpmatrix","category":"section"},{"location":"tutorial/utils/#Transposition","page":"Utils","title":"Transposition","text":"Transposition exchanges rows and columns of a microstate. Let mathcalT denote the transposition operator:\n\nmathcalTmathbfM = beginpmatrix\na  d  g \nb  e  f \nc  f  i\nendpmatrix\n\nUsing the same example microstate with identifier I = 237, transposition is performed via the Transpose operator:\n\ntransposition = Transpose(shape)\noperate(transposition, 237)\n\nThe resulting microstate has decimal identifier I = 231 corresponding to:\n\nmathcalTmathbfM = beginpmatrix\n0  1  1 \n0  0  1 \n1  1  0\nendpmatrix","category":"section"},{"location":"tutorial/utils/#RecurrenceMicrostatesAnalysis.Parameter","page":"Utils","title":"RecurrenceMicrostatesAnalysis.Parameter","text":"Parameter\n\nAbstract supertype for free parameters that can be optimized using RMA.\n\nImplementations\n\nThreshold\n\n\n\n\n\n","category":"type"},{"location":"tutorial/utils/#RecurrenceMicrostatesAnalysis.optimize","page":"Utils","title":"RecurrenceMicrostatesAnalysis.optimize","text":"optimize(param::Parameter, qm::QuantificationMeasure, args...)\n\nOptimize a free Parameter using the specified QuantificationMeasure.\n\nwarning: Warning\nThe optimize function may compute multiple distributions and can be computationally expensive. Avoid calling it inside performance-critical loops.\n\n\n\n\n\n","category":"function"},{"location":"tutorial/utils/#RecurrenceMicrostatesAnalysis.Threshold","page":"Utils","title":"RecurrenceMicrostatesAnalysis.Threshold","text":"Threshold <: Parameter\n\nThreshold parameter used to classify two states as recurrent or non-recurrent.\n\nThe Threshold parameter can be optimized using the optimize function in combination with specific QuantificationMeasures:\n\noptimize(::Threshold, qm::RecurrenceEntropy, [x], n::int; kwargs...)\noptimize(::Threshold, qm::Disorder{N}, [x]; kwargs...)\n\ncompat: Compat\nThreshold optimization using RMA is currently supported only for the RecurrenceEntropy and Disorder quantification measures.\n\nArguments\n\nqm: A QuantificationMeasure used to determine the optimal threshold. Supported measures are RecurrenceEntropy and Disorder.\n[x]: Input data used to estimate the optimal threshold.\nn: Size of the square microstate used in the optimization.\n\nReturns\n\nA Tuple{Float64, Float64}, where:\n\nthe first element is the optimal threshold value, and\nthe second element is the value of the corresponding QuantificationMeasure at the optimum.\n\nKeyword Arguments\n\nrate: Sampling rate. Default is 0.05.\nsampling: Sampling mode. Default is SRandom.\nth_max_range: Fraction of the maximum distance defining the upper bound of the threshold search range. Default is 0.5.\nth_start: Initial value of the threshold search range. Default is 1e-6.\nfraction: Interaction fraction controlling the refinement process. Default is 5.\n\nExample\n\nusing Distributions, RecurrenceMicrostatesAnalysis\ndata = StateSpaceSet(rand(Uniform(0, 1), 1000))\nth, s = optimize(Threshold(), RecurrenceEntropy(), data, 3)\n\n\n\n\n\n","category":"type"},{"location":"tutorial/utils/#RecurrenceMicrostatesAnalysis.Operation","page":"Utils","title":"RecurrenceMicrostatesAnalysis.Operation","text":"Operation\n\nAbstract supertype for operations that can be applied to recurrence microstates or to recurrence microstate distributions.\n\nImplementations:\n\nPermuteColumns\nPermuteRows\nTranspose\n\n\n\n\n\n","category":"type"},{"location":"tutorial/utils/#RecurrenceMicrostatesAnalysis.operate","page":"Utils","title":"RecurrenceMicrostatesAnalysis.operate","text":"operate(op::Operation, [...])\n\nApply the operation defined by the given Operation instance.\n\nThe accepted arguments ([...]) depend on the specific operation implementation.\n\n\n\n\n\n","category":"function"},{"location":"tutorial/utils/#RecurrenceMicrostatesAnalysis.PermuteRows","page":"Utils","title":"RecurrenceMicrostatesAnalysis.PermuteRows","text":"PermuteRows{R, C} <: Operation\n\nOperation that permutes the rows of a microstate mathbfM.\n\nTo initialize a PermuteRows operation, a rectangular microstate shape must be provided via a Rect structure:\n\nPermuteRows(::Rect2{R, C, B, E})\n\nExamples\n\nPermuteRows(Rect(3, 3))     #   Microstate 3 x 3\nPermuteRows(Rest(3, 1))     #   Microstate 3 x 1 (it is a column)\n\nThis operation is applied via the operate function:\n\noperate(::PermuteRows, I::Int, œÉ::Vector{Int})\n\nArguments\n\nop: A PermuteRows operation.\nI: Decimal identifier of the microstate (1-based).\nœÉ: Permutation of rows to be applied.\n\nReturns\n\nThe resulting microstate binary identifier (1-based).\n\n\n\n\n\n","category":"type"},{"location":"tutorial/utils/#RecurrenceMicrostatesAnalysis.PermuteColumns","page":"Utils","title":"RecurrenceMicrostatesAnalysis.PermuteColumns","text":"PermuteColumns{R, C} <: Operation\n\nOperation that permutes the columns of a microstate mathbfM.\n\nTo initialize a PermuteColumns operation, a rectangular microstate shape must be provided via a Rect structure:\n\nPermuteColumns(::Rect2{R, C, B, E}; S::Vector{Vector{Int}} = collect(permutations(1:C))\n\nHere, the keyword argument S defines the set S_n of column permutations. The PermuteColumns struct precomputes the column permutations for each row of the microstate. These precomputed permutations can be accessed via the field Q.\n\nExamples\n\nPermuteColumns(Rect(3, 3))     #   Microstate 3 x 3\nPermuteColumns(Rest(1, 3))     #   Microstate 1 x 3 (it is a line)\n\nThis operation is applied via the operate function:\n\noperate(op::PermuteColumns, I::Int, Qi::Int)\n\nArguments\n\nop: A PermuteColumns operation.\nI: Decimal identifier of the microstate (1-based).\nQi: Index of the permutation in the set S.\n\nReturns\n\nThe resulting microstate decimal identifier (1-based).\n\n\n\n\n\n","category":"type"},{"location":"tutorial/utils/#RecurrenceMicrostatesAnalysis.Transpose","page":"Utils","title":"RecurrenceMicrostatesAnalysis.Transpose","text":"Transpose{R, C} <: Operation\n\nOperation that transposes a microstate mathbfM.\n\nTo initialize a Transpose operation, a rectangular microstate shape must be provided via a Rect structure:\n\nTranspose(::Rect2{R, C, B, E})\n\nExamples\n\nTranspose(Rect(3, 3))     # 3 x 3 microstate\n\nThis operation is applied via the operate function:\n\noperate(::Transpose, I::Int)\n\nArguments\n\nop: A Transpose operation.\nI: DEcima identifier of the microstate (1-based).\n\nReturns\n\nThe resulting microstate decimal identifier (1-based).\n\n\n\n\n\n","category":"type"},{"location":"tutorial/shapes_and_sampling/#Shapes-and-Sampling","page":"Shapes and Sampling","title":"Shapes and Sampling","text":"This section describes the microstate shapes used in Recurrence Microstates Analysis (RMA) and the sampling strategies employed to construct histograms and distributions.","category":"section"},{"location":"tutorial/shapes_and_sampling/#Variations-of-microstates-shapes","page":"Shapes and Sampling","title":"Variations of microstates shapes","text":"A microstate shape defines the local recurrence pattern extracted from a recurrence plot. In RecurrenceMicrostatesAnalysis.jl, microstate shapes are represented by subtypes of MicrostateShape.\n\nA MicrostateShape specifies:\n\nwhich relative positions are sampled to evaluate recurrences, and\nhow the resulting binary recurrence pattern is mapped to a decimal representation.\n\nThe internal conversion from a microstate pattern to its decimal index is performed by the compute_motif function.","category":"section"},{"location":"tutorial/shapes_and_sampling/#Implemented-microstates-shapes","page":"Shapes and Sampling","title":"Implemented microstates shapes","text":"","category":"section"},{"location":"tutorial/shapes_and_sampling/#Sampling-strategies","page":"Shapes and Sampling","title":"Sampling strategies","text":"The sampling strategy determines which microstates are selected during histogram or distribution construction.\n\nSampling behavior is defined by subtypes of SamplingMode, while the set of valid sampling positions is determined by a SamplingSpace.","category":"section"},{"location":"tutorial/shapes_and_sampling/#Implemented-sampling-modes","page":"Shapes and Sampling","title":"Implemented sampling modes","text":"","category":"section"},{"location":"tutorial/shapes_and_sampling/#RecurrenceMicrostatesAnalysis.MicrostateShape","page":"Shapes and Sampling","title":"RecurrenceMicrostatesAnalysis.MicrostateShape","text":"MicrostateShape\n\nAbstract supertype defining the basic structure and layout of a microstate (or motif).\n\nA MicrostateShape specifies which relative positions are retrieved from the data to evaluate recurrences, and how these binary recurrence values are interpreted and mapped to a decimal representation for counting.\n\nAll subtypes of MicrostateShape must include a field expr, which defines the RecurrenceExpression used to compute recurrences.\n\nImplementations\n\nDiagonal\nRect\nTriangle\n\n\n\n\n\n","category":"type"},{"location":"tutorial/shapes_and_sampling/#RecurrenceMicrostatesAnalysis.Rect","page":"Shapes and Sampling","title":"RecurrenceMicrostatesAnalysis.Rect","text":"Rect <: MicrostateShape\n\nDefine a rectangular microstate shape.\n\nRect can represent either a two-dimensional microstate (identified as Rect2, used for Recurrence Plots and Cross-Recurrence Plots) or an N-dimensional microstate (identified as RectN, used for spatial data).\n\nRect2 (time-series data)\n\nA 2D rectangular microstate can be initialized using either of the following constructors:\n\nRect(expr::E; rows = 2, cols = 2, B = 2)\nRect(rows::Int, cols::Int; expr = Standard(0.27), B = 2)\n\nHere, rows and columns define the rectangle dimensions, expr is the RecurrenceExpression used to evaluate recurrences, and B is the base used to encode microstate elements (typically 2, representing recurrence or non-recurrence).\n\nRectangular microstates can be specialized to define common patterns such as lines, columns, and squares:\n\nline = Rect(expr; rows = n, cols = 1)\ncolumn = Rect(expr; rows = 1, cols = n)\nsquare = Rect(expr; rows = n, cols = n)\n\nSince square microstates are frequently used, a convenience constructor is also provided:\n\nRect(expr::E, N; B = 2)\n\nwhere N defines the size of the square microstate. For example:\n\nsquare = Rect(expr, n)\n\nRectN (spatial data)\n\nFor N-dimensional structures, typically used with spatial data, the RectN variant can be initialized as:\n\nRect(expr::E, structure::NTuple{D, Int}; B = 2)\n\nHere, structure defines the size of the microstate along each dimension. For example:\n\nnrect = Rect(expr, (2, 1, 2, 1))\n\nThis form is suitable for N-dimensional spatial data, such as images or volumetric datasets.\n\n\n\n\n\n","category":"type"},{"location":"tutorial/shapes_and_sampling/#RecurrenceMicrostatesAnalysis.Triangle","page":"Shapes and Sampling","title":"RecurrenceMicrostatesAnalysis.Triangle","text":"Triangle{N, B, E<:RecurrenceExpression} <: MicrostateShape\n\nTriangle{N, B, E<:RecurrenceExpression} <: MicrostateShape\n\nDefine a triangular microstate shape, originally introduced by Hirata in 2021 (Hirata, 2021).\n\nConstructor\n\nTriangle(expr::E, N::Int; B::Int = 2)\n\nwhere expr is the RecurrenceExpression used to evaluate recurrences and N defines the size of the triangular microstate.\n\nExample\n\nn = 3\ntriangle = Triangle(expr, n)\n\nThe corresponding microstate structure is given by:\n\nbeginpmatrix\nR_ij  R_ij + 1  R_ij + 2 \n  R_i + 1j + 1  R_i + 1j + 2 \n   R_i + 2j + 2 \nendpmatrix\n\ncompat: Compat\nTriangular microstate shape is not compatible with spatial data.\n\n\n\n\n\n","category":"type"},{"location":"tutorial/shapes_and_sampling/#RecurrenceMicrostatesAnalysis.Diagonal","page":"Shapes and Sampling","title":"RecurrenceMicrostatesAnalysis.Diagonal","text":"Diagonal <: MicrostateShape\n\nDefine a diagonal microstate shape, which captures recurrences along diagonals of a Recurrence Plot (RP).\n\nConstructor\n\nDiagonal(expr::E, N::Int; B::Int = 2)\n\nwhere expr is the RecurrenceExpression used to evaluate recurrences and N defines the length of the diagonal microstate.\n\nExample\n\ndiagonal = Diagonal(expr, 3)\n\ninfo: Info\nDiagonal microstates are compatible with spatial data. However, they do not capture hyper-diagonals in Spatial Recurrence Plots (SRP). Only diagonals defined by sequential recurrences are supported, such as:R_i_1i_2j_1j_2 R_i_1 + 1i_2 + 1j_1 + 1j_2 + 1 R_i_1 + 2i_2 + 2j_1 + 2j_2 + 2 ldots R_i_1 + n - 1i_2 + n - 1j_1 + n - 1j_2 + n - 1\n\n\n\n\n\n","category":"type"},{"location":"tutorial/shapes_and_sampling/#RecurrenceMicrostatesAnalysis.SamplingMode","page":"Shapes and Sampling","title":"RecurrenceMicrostatesAnalysis.SamplingMode","text":"SamplingMode\n\nAbstract supertype defining how the initial position (i j) of each microstate is selected during the construction of recurrence microstate distributions.\n\nImplementations\n\nSRandom\nFull\n\n\n\n\n\n","category":"type"},{"location":"tutorial/shapes_and_sampling/#RecurrenceMicrostatesAnalysis.SamplingSpace","page":"Shapes and Sampling","title":"RecurrenceMicrostatesAnalysis.SamplingSpace","text":"SamplingSpace\n\nDefine the range of valid indices used to sample the initial positions (i j) of microstates.\n\n\n\n\n\n","category":"type"},{"location":"tutorial/shapes_and_sampling/#RecurrenceMicrostatesAnalysis.SRandom","page":"Shapes and Sampling","title":"RecurrenceMicrostatesAnalysis.SRandom","text":"SRandom{F<:Real} <: SamplingMode\n\nSampling mode that randomly selects microstate positions (i j) within the SamplingSpace.\n\nConstructors\n\nSRandom(num_samples::Int)\nSRandom(ratio::Union{Float32, Float64})\n\nThe sampling mode can be initialized either by specifying the exact number of microstates to sample or by providing a ratio of the total number of possible microstates.\n\nExamples\n\ns = SRandom(1000)   # Specify the exact number of sampled microstates\ns = SRandom(0.05)   # Specify a ratio of the total possible microstates\n\n\n\n\n\n","category":"type"},{"location":"tutorial/shapes_and_sampling/#RecurrenceMicrostatesAnalysis.Full","page":"Shapes and Sampling","title":"RecurrenceMicrostatesAnalysis.Full","text":"Full <: SamplingMode\n\nSampling mode that selects all possible microstates within the SamplingSpace.\n\nConstructor\n\ns = Full()\n\nwarning: Warning\nThe Full sampling mode is not supported for spatial data.\n\n\n\n\n\n","category":"type"},{"location":"tutorial/quantifiers/#Quantifiers","page":"Quantifiers","title":"Quantifiers","text":"Quantifiers are measures used to characterize specific properties of a dynamical system. Currently, Recurrence Microstates Analysis (RMA) provides five quantifiers that can be computed or estimated from a microstate distribution.\n\nThree of these correspond to classical Recurrence Quantification Analysis (RQA) measures: recurrence rate, determinism, and laminarity. One is an information-theoretic entropy measure. The final quantifier is disorder, which is defined directly in terms of the microstate distribution and exploits symmetry properties of recurrence structures.\n\nAll quantifiers implemented in the package inherit from QuantificationMeasure, and their computation is performed using the measure function.","category":"section"},{"location":"tutorial/quantifiers/#Recurrence-microstates-entropy","page":"Quantifiers","title":"Recurrence microstates entropy","text":"The Recurrence Microstates Entropy (RME) was introduced in 2018 and marks the starting point of the RMA framework (Corso et al., 2018). It is defined as the Shannon entropy of the RMA distribution:\n\nRME = -sum_i = 1^2^sigma p_i^(N) ln p_i^(N)\n\nwhere n is the microstate size, sigma is the number of recurrence elements constrained within the microstate (e.g. sigma = n^2 for square microstates), and p_i^(N) denotes the probability of the microstate with decimal representation i.\n\nIn RecurrenceMicrostatesAnalysis.jl, the RME is implemented by the RecurrenceEntropy struct.\n\nSince the output of the distribution function is a Probabilities object, the package also supports other information or complexity measures provided by ComplexityMeasures.jl.","category":"section"},{"location":"tutorial/quantifiers/#Quick-example","page":"Quantifiers","title":"Quick example","text":"As an example, consider a uniform random process. The RME as a function of the threshold can be computed and visualized as follows:\n\nusing RecurrenceMicrostatesAnalysis, Distributions, CairoMakie\n\ndata_len = 10000\nresolution = 50\n\ndata = StateSpaceSet(rand(Uniform(0, 1), data_len))\nthres_range = range(0, 1, resolution)\nresults = zeros(Float64, resolution)\n\nfor i ‚àà eachindex(results)\n    dist = distribution(data, thres_range[i], 4)\n    results[i] = measure(RecurrenceEntropy(), dist)\nend\n\nresults ./= maximum(results)\nscatterlines(thres_range, results)","category":"section"},{"location":"tutorial/quantifiers/#Recurrence-rate","page":"Quantifiers","title":"Recurrence rate","text":"The Recurrence Rate (RR) quantifies the density of recurrence points in a recurrence plot (Webber and Marwan, 2015). In standard RQA, it is defined as\n\nRR = frac1K^2 sum_ij=1^K R_ij\n\nwhere K is the length of the time series.\n\nWhen estimated using RMA, RR is defined as the expected recurrence rate over the microstate distribution:\n\nRR = sum_i = 1^2^sigma p_i^(N) RR_i^(N)\n\nwhere RR_i^(N) denotes the recurrence rate of the i-th microstate. For square microstates, this quantity is given by\n\nRR_i^(N) = frac1sigma sum_jk=1^N M_jk^i (N)\n\nwith mathbfM^i (N) denoting the microstate structure corresponding to index i.\n\nIn RecurrenceMicrostatesAnalysis.jl, RR is implemented by RecurrenceRate struct.","category":"section"},{"location":"tutorial/quantifiers/#Determinism","page":"Quantifiers","title":"Determinism","text":"In standard RQA, Determinism (DET) measures the fraction of recurrence points forming diagonal line structures (Webber and Marwan, 2015):\n\nDET = fracsum_l=d_min^K lH_D(l)sum_ij=1^K R_ij\n\nwhere H_D(l) is the histogram of diagonal line lengths,\n\nH_D(l)=sum_ij1^K(1-R_i-1j-1)(1-R_i+lj+l)prod_k=0^l-1R_i+kj+k\n\nThe estimation of DET using RMA is based on the work \"Density-Based Recurrence Measures from Microstates\" (da¬†Cruz et al., 2025). In that work, the DET expression is rewritten as\n\nDET = 1 - frac1K^2RRsum_l=1^l_min-1 lH_D(l)\n\nand the diagonal histogram H_D(l) is related to the RMA distribution through correlations between microstate structures:\n\nfracH_D(l)(K-l-1)^2=vec d^(l)cdotmathcalR^(l+2)vec p^(l+2)\n\nFor the commonly used case l_min = 2 (currently the only case implemented in the package), this leads to the approximation\n\nDETapprox 1 - fracvec d^(1)cdotmathcalR^(3)vec p^3RR\n\nThe correlation term vec d^(1)cdotmathcalR^(3)vec p^3 can be simplified by explicitly identifying the microstates selected by vec d^(1). These correspond to microstates of the form\n\nbeginpmatrix\nxi  xi  0 \nxi  1  xi \n0  xi  xi \nendpmatrix\n\nwhere xi denotes an unconstrained entry. There are 64 such microstates among the 512 possible square microstates of size N = 3.  Defining the class C_D as the set of microstates with this structure, DET can be estimated as:\n\nDETapprox 1 - fracsum_iin C_D p_i^(3)RR\n\nwhere p_i^(3) is the probability of the i-th microstate in an RMA distribution of square microstates with size N = 3.\n\nA futher simplification can be obtained by defining Diagonal-shaped microstates (Ferreira et al., 2025).  In the structure above, the unconstrained entries xi may represent either recurrences or non-recurrences, leading to the need for all 64 combinations. Diagonal microstates focus directly on the relevant information, namely the diagonal pattern 010. In this case, DET can be approximated as\n\nDETapprox 1 - fracp_3^(3)RR\n\nwhere p_3^(3) is the probability of observing the diagonal motif 010.\n\nIn RecurrenceMicrostatesAnalysis.jl, the computation of DET is implemented by the Determinism struct.","category":"section"},{"location":"tutorial/quantifiers/#Laminarity","page":"Quantifiers","title":"Laminarity","text":"Laminarity (LAM) is another classical RQA quantifier that measures the proportion of recurrence points forming vertical (line) structures in a recurrence plot.  It is defined as\n\nLAM = fracsum_l=v_min^K lH_V(l)sum_ij=1^K R_ij\n\nwhere\n\nH_V(l)=sum_ij1^K(1-R_ij-1)(1-R_ij+l)prod_k=0^l-1R_ij+k\n\nThe estimation of LAM using RMA is also based on the work \"Density-Based Recurrence Measures from Microstates\" (da¬†Cruz et al., 2025) and follows the same logical used for determinsm. In this case, the estimation requires microstates of the form\n\nbeginpmatrix\n0  1  0 \nxi  xi  xi \nxi  xi  xi \nendpmatrix\n\nwhich defines the class C_L of microstates used to estimate LAM as\n\nLAMapprox 1 - fracsum_iin C_L p_i^(3)RR\n\nAs with determinism, this process can be further simplified by defining a line motif (Ferreira et al., 2025), which captures only the relevant information, namely vertical line patterns of the form 010 in the recurrence plot. In this case, LAM can be approximated as\n\nLAMapprox 1 - fracp_3^(3)RR\n\nwhere p_3^(3) denotes the probability of observing the line motif 010.\n\nIn RecurrenceMicrostatesAnalysis.jl, the computation of LAM is implemented by the Laminarity struct.","category":"section"},{"location":"tutorial/quantifiers/#Disorder","page":"Quantifiers","title":"Disorder","text":"The disorder quantifier is implemented based on the work ‚ÄúQuantifying Disorder in Data‚Äù (Flauzino et al., 2025).  It is a novel and powerful tool for data analysis, allowing the distinction between stochastic and deterministic time series, as well as between different types of stochastic dynamics, such as white, pink, and red Gaussian noise.\n\nDisorder is implemented using square recurrence microstates, which can be permuted by rows and columns and transposed (see Permutations and Transposition).  This procedure generates a set of equivalent microstates given by\n\nmathcalM_a(mathbfM) = bigcup_sigma_isigma_jin S_NmathcalL_sigma_jmathcalTmathcalL_sigma_imathbfMquadmathcalTmathcalL_sigma_jmathcalTmathcalL_sigma_imathbfM\n\nThis defines an equivalence class of microstates denoted by mathcalM_a.\n\nThe probability of observing a given microstate mathbf M^i(N) in the recurrence plot, denoted by p_i^(N), is computed using RecurrenceMicrostatesAnalysis.jl. To compute disorder, the probabilities of microstates belonging to the same class must be normalized. Thus, for mathbf M^i (N) in mathcalM_a, the normalized probability within the class is defined as\n\np_i^(a N) = fracp_i^(N)sum_mathbfM_j^(N) in mathcalM_ap_j^(N)\n\nThe information entropy associated with the probability distribution of microstates in the class mathcalM_a is then defined as\n\nxi_a(varepsilon) stackrelmathrmdef= -sum_mathbfM_i^(N) in mathcalM_a p_i^(a N) ln p_i^(a N)\n\nThis entropy is normalized by ln m_a, where m_a is the number of microstates in the class mathcalM_a. Using RecurrenceMicrostatesAnalysis.jl, the normalized quantity xi_a(varepsilon)  ln m_a can be computed as\n\nusing Distributions, RecurrenceMicrostatesAnalysis\ndata = StateSpaceSet(rand(Uniform(0, 1), 1000))\ndist = distribution(data, 0.27, 4; sampling = Full())\n\nclass = 102\nmeasure(Disorder(4), class, dist)\n\nThe total entropy over all classes for a given threshold varepsilon is defined as\n\nxi(varepsilon) stackrelmathrmdef= frac1A sum_a = 1^A fracxi_a(varepsilon)ln m_a\n\nwhere A is the number of contributing classes and defines the maximum possible amplitude. This normalization factor can also be computed using RecurrenceMicrostatesAnalysis.jl:\n\nA = RecurrenceMicrostatesAnalysis.get_disorder_norm_factor(Disorder(4), data)\n\nAnd the total entropy:\n\nmeasure(Disorder(4), dist, A)\n\nFinally, the the disorder index via symmetry in recurrence microstates (DISREM), or simply disorder, is defined as\n\nXi = max_varepsilon xi(varepsilon)\n\nIn RecurrenceMicrostatesAnalysis.jl, this quantifier is implemented by the Disorder struct.","category":"section"},{"location":"tutorial/quantifiers/#Computing-disorder-for-compatible-time-series","page":"Quantifiers","title":"Computing disorder for compatible time series","text":"Consider a scenario in which a long time series is split into multiple windows. RecurrenceMicrostatesAnalysis.jl provides a compact interface to compute the disorder for each window.\n\nAs an example, consider a time series with 50,000 points consisting of a sine wave with added white noise, alternating every five windows:\n\nfunction data_gen(t)\n    x = sin.(6*œÄ .* t)\n\n    count = 0\n    for i in 1:1000:50_000\n        if count < 5\n            x[i:(i-1)+1000] .+= rand(Normal(0, 0.25), 1000)\n        elseif count ‚â• 9\n            count = -1\n        end\n\n        count += 1\n    end\n\n    return x\nend\n\nusing CairoMakie\n\nt = range(0, 50, 50_000)\ndata = data_gen(t)\n\nlines(t, data)\n\nThe disorder can be computed using the following method:\n\nmeasure(settings::Disorder{N}, dataset::Vector{StateSpaceSet}, th_min::Float64, th_max::Float64)\n\nTo apply it, the time series must first be split into a vector of StateSpaceSet objects:\n\nwindows = [ data[(i + 1):(i + 1000)] for i in 0:1000:(length(data) - 1000)]\ndataset = Vector{StateSpaceSet}(undef, length(windows))\nfor i ‚àà eachindex(windows)\n    dataset[i] = StateSpaceSet(windows[i])\nend\n\ndataset\n\nNext, the threshold range th_min and th_max must be defined. There are two possible approaches:\n\nUse the full range of admissible threshold values by setting th_min = 0 and th_max = maximum(pairwise(Euclidean(), data, data)), and choosing a small step size via the num_tests keywork argument (e.g., num_tests = 1000). This approach yields the global maximum disorder values but can be computationally expensive.\nUse a small interval centered around a known threshold value. This is the recommended approach and is adopted here.\n\nTo obtain a suitable reference threshold, we select a subset of windows and compute the optimal disorder threshold using the optimize function:\n\nusing Statistics\n\nfunction find_threshold(disorder, data)\n    ths = zeros(Float64, 10)\n    for i ‚àà eachindex(ths)\n        idx = rand(1:length(windows))\n        ths[i] = optimize(Threshold(), disorder, data[idx])[1]\n    end\n\n    Œº = mean(ths)\n    œÉ = std(ths)\n\n    return (max(0.0, Œº - 1.5 * œÉ), Œº + 1.5 * œÉ)\nend\n\ndis = Disorder(4)\nth_min, th_max = find_threshold(dis, dataset)\n\nFinally, the disorder can be computed for all windows using the measure function:\n\nresults = measure(dis, dataset, th_min, th_max)\n\nscatterlines(results)\n\ninfo: Info\nWhen computing Disorder for compatible time series, the same threshold range is used for all windows.  However, the disorder value of each window corresponds to the maximum over that range, and therefore the optimal threshold may differ between windows.\n\ntip: Tip\nDisorder can also be computed using the GPU backend:measure(settings::Disorder{N}, dataset::Vector{<:AbstractGPUVector{SVector{D, Float32}}}, th_min::Float32, th_max::Float32)The procedure is identical, but each window must first be transferred to the GPU:for i ‚àà eachindex(windows)\n    dataset[i] = StateSpaceSet(Float32.(windows[i])) |> CuVector\nend","category":"section"},{"location":"tutorial/quantifiers/#RecurrenceMicrostatesAnalysis.QuantificationMeasure","page":"Quantifiers","title":"RecurrenceMicrostatesAnalysis.QuantificationMeasure","text":"QuantificationMeasure\n\nAbstract supertype defining an RQA or RMA quantification measure.\n\nAll quantifiers implemented in the package subtype QuantificationMeasure and define their computation via the measure function.\n\nImplementations\n\nDeterminism\nDisorder\nLaminarity\nRecurrenceEntropy\nRecurrenceRate\n\n\n\n\n\n","category":"type"},{"location":"tutorial/quantifiers/#RecurrenceMicrostatesAnalysis.measure","page":"Quantifiers","title":"RecurrenceMicrostatesAnalysis.measure","text":"measure(qm::QuantificationMeasure, [...])\n\nCompute the quantification measure defined by the given QuantificationMeasure instance.\n\nThe accepted arguments ([...]) depend on the specific quantifier implementation.\n\n\n\n\n\n","category":"function"},{"location":"tutorial/quantifiers/#RecurrenceMicrostatesAnalysis.RecurrenceEntropy","page":"Quantifiers","title":"RecurrenceMicrostatesAnalysis.RecurrenceEntropy","text":"RecurrenceEntropy <: QuantificationMeasure\n\nDefine the Recurrence Microstates Entropy (RME) quantification measure (Corso et al., 2018).\n\nRME can be computed either from a distribution of recurrence microstates or directly from time-series data. In both cases, the computation is performed via the measure function.\n\nUsing a distribution\n\nmeasure(::RecurrenceEntropy, dist::Probabilities)\n\nArguments\n\ndist: A distribution of recurrence microstates.\n\nReturns\n\nA Float64 corresponding to the RME computed using the Shannon entropy.\n\nExamples\n\nusing RecurrenceMicrostatesAnalysis, Distributions\ndata = StateSpaceSet(rand(Uniform(0, 1), 1000))\ndist = distribution(data, 0.27, 3)\nrme = measure(RecurrenceEntropy(), dist)\n\nUsing a time series\n\nmeasure(::RecurrenceEntropy, [x]; kwargs...)\n\nArguments\n\n[x]: Time-series data provided as an StateSpaceSet.\n\nReturns\n\nA Float64 corresponding to the maximum RME computed using the Shannon entropy.\n\nKeyword Arguments\n\nN: Integer defining the microstate size. The default value is 3.\n\nExamples\n\nusing RecurrenceMicrostatesAnalysis, Distributions\ndata = StateSpaceSet(rand(Uniform(0, 1), 1000))\nrme = measure(RecurrenceEntropy(), data; N = 4)\n\n\n\n\n\n","category":"type"},{"location":"tutorial/quantifiers/#RecurrenceMicrostatesAnalysis.RecurrenceRate","page":"Quantifiers","title":"RecurrenceMicrostatesAnalysis.RecurrenceRate","text":"RecurrenceRate <: QuantificationMeasure\n\nDefine the Recurrence Rate (RR) quantification measure.\n\nRR can be computed either from a distribution of recurrence microstates or directly from time-series data. In both cases, the computation is performed via the measure function.\n\nUsing a distribution\n\nmeasure(::RecurrenceRate, dist::Probabilities)\n\nArguments\n\ndist: A distribution of recurrence microstates.\n\nReturns\n\nA Float64 corresponding to the estimated recurrence rate.\n\nExamples\n\nusing RecurrenceMicrostatesAnalysis, Distributions\ndata = StateSpaceSet(rand(Uniform(0, 1), 1000))\ndist = distribution(data, 0.27, 3)\nrr = measure(RecurrenceRate(), dist)\n\nUsing a time series\n\nmeasure(::RecurrenceRate, [x]; kwargs...)\n\nArguments\n\n[x]: Time-series data provided as a StateSpaceSet.\n\nReturns\n\nA Float64 corresponding to the estimated recurrence rate.\n\nKeyword Arguments\n\nN: Integer defining the microstate size. The default value is 3.\nthreshold: Threshold used to compute the RMA distribution. By default, this is chosen as   the threshold that maximizes the recurrence microstate entropy (RME).\n\nExamples\n\nusing RecurrenceMicrostatesAnalysis, Distributions\ndata = StateSpaceSet(rand(Uniform(0, 1), 1000))\nrme = measure(RecurrenceRate(), data; N = 4)\n\n\n\n\n\n","category":"type"},{"location":"tutorial/quantifiers/#RecurrenceMicrostatesAnalysis.Determinism","page":"Quantifiers","title":"RecurrenceMicrostatesAnalysis.Determinism","text":"Determinism <: QuantificationMeasure\n\nDefine the Determinism (DET) quantification measure.\n\nDET can be computed either from a distribution of recurrence microstates or directly from time-series data. In both cases, the computation is performed via the measure function.\n\nUsing a distribution\n\nmeasure(::Determinism, dist::Probabilities)\n\nArguments\n\ndist: A distribution of recurrence microstates. The distribution must be computed from   square or diagonal microstates of size 3.\n\nReturns\n\nA Float64 corresponding to the estimated determinism.\n\nExamples\n\nUsing square microstates\n\nusing RecurrenceMicrostatesAnalysis, Distributions\ndata = StateSpaceSet(rand(Uniform(0, 1), 1000))\ndist = distribution(data, 0.27, 3)\ndet = measure(Determinism(), dist)\n\nUsing diagonal microstates\n\nusing RecurrenceMicrostatesAnalysis, Distributions\ndata = StateSpaceSet(rand(Uniform(0, 1), 1000))\ndist = distribution(data, Diagonal(Standard(0.27), 3))\ndet = measure(Determinism(), dist)\n\nUsing a time series\n\nmeasure(::Determinism, [x]; kwargs...)\n\nArguments\n\n[x]: Time-series data provided as a StateSpaceSet.\n\nReturns\n\nA Float64 corresponding to the estimated determinism.\n\nKeyword Arguments\n\nthreshold: Threshold used to compute the RMA distribution. By default, this is chosen as   the threshold that maximizes the recurrence microstate entropy (RME).\n\nExamples\n\nusing RecurrenceMicrostatesAnalysis, Distributions\ndata = StateSpaceSet(rand(Uniform(0, 1), 1000))\ndet = measure(Determinism(), data)\n\nnote: Note\nWhen time-series data are provided directly, RecurrenceMicrostatesAnalysis.jl uses Diagonal microstates by default.\n\n\n\n\n\n","category":"type"},{"location":"tutorial/quantifiers/#RecurrenceMicrostatesAnalysis.Laminarity","page":"Quantifiers","title":"RecurrenceMicrostatesAnalysis.Laminarity","text":"Laminarity <: QuantificationMeasure\n\nDefine the Laminarity (LAM) quantification measure.\n\nLAM can be computed either from a distribution of recurrence microstates or directly from time-series data. In both cases, the computation is performed via the measure function.\n\nUsing a distribution\n\nmeasure(::Laminarity, dist::Probabilities)\n\nArguments\n\ndist: A distribution of recurrence microstates. The distribution must be computed from   square or line microstates of size 3.\n\nReturns\n\nA Float64 corresponding to the estimated laminarity.\n\nExamples\n\nUsing square microstates\n\nusing RecurrenceMicrostatesAnalysis, Distributions\ndata = StateSpaceSet(rand(Uniform(0, 1), 1000))\ndist = distribution(data, 0.27, 3)\nlam = measure(Laminarity(), dist)\n\nUsing line microstates:\n\nusing RecurrenceMicrostatesAnalysis, Distributions\ndata = StateSpaceSet(rand(Uniform(0, 1), 1000))\ndist = distribution(data, Rect(Standard(0.27); rows = 1, cols = 3))\nlam = measure(Laminarity(), dist)\n\nUsing a time series\n\nmeasure(::Laminarity, [x]; kwargs...)\n\nArguments\n\n[x]: Time-series data provided as a StateSpaceSet.\n\nReturns\n\nA Float64 corresponding to the estimated laminarity.\n\nKeyword Arguments\n\nthreshold: Threshold used to compute the RMA distribution. By default, this is chosen as   the threshold that maximizes the recurrence microstate entropy (RME).\n\nExamples\n\nusing RecurrenceMicrostatesAnalysis, Distributions\ndata = StateSpaceSet(rand(Uniform(0, 1), 1000))\nlam = measure(Laminarity(), data)\n\nnote: Note\nWhen time-series data are provided directly, RecurrenceMicrostatesAnalysis.jl uses line microstates by default.\n\n\n\n\n\n","category":"type"},{"location":"tutorial/quantifiers/#RecurrenceMicrostatesAnalysis.Disorder","page":"Quantifiers","title":"RecurrenceMicrostatesAnalysis.Disorder","text":"Disorder{N} <: QuantificationMeasure\n\nDefine the Disorder quantification measure for microstates of size N (Flauzino et al., 2025).\n\nThe Disorder struct stores a set of labels that identify the microstates belonging to each equivalence class mathcalM_a.\n\nConstructor\n\nDisorder(N)\n\nHere, N must be equal to 2, 3, 4, or 5. Computing disorder for larger values of N is currently not supported, as it would require a prohibitive amount of memory with the current implementation.\n\nThe computation of Disorder is performed via the measure function:\n\nmeasure(settings::Disorder{N}, [x]; kwargs...)\n\nArguments\n\n[x]: Time-series data provided as a StateSpaceSet.\n\nReturns\n\nA Float64 corresponding to the disorder value (Xi).\n\nKeyword Arguments\n\nth: Reference threshold used to maximize disorder. To improve computational performance,   this value limits the search range of thresholds. By default, it is set to the threshold   that maximizes disorder for a sampling rate of 5.\nth_min: Minimum threshold defining the search range. By default, this is set to 0.85 * th.\nth_max: Maximum threshold defining the search range. By default, this is set to 1.25 * th.\nnum_tests: Number of threshold values evaluated within the specified range. The default value is 40.\n\nExamples\n\nusing RecurrenceMicrostatesAnalysis, Distributions\ndata = StateSpaceSet(rand(Uniform(0, 1), 1000))\ndisrem = measure(Disorder(4), data)\n\n\n\n\n\n","category":"type"},{"location":"#RecurrenceMicrostatesAnalysis.jl","page":"Welcome","title":"RecurrenceMicrostatesAnalysis.jl","text":"todo: GitHub\nRecurrenceMicrostatesAnalysis.jl is an open-source package available on GitHub. If you find this package useful, please consider giving it a star on GitHub and don't forget to cite our work. üòâ","category":"section"},{"location":"#About-the-documentation","page":"Welcome","title":"About the documentation","text":"The documentation of RecurrenceMicrostatesAnalysis.jl is designed to explain how to use the package while also introducing the theoretical background of the RMA framework. The bibliography used throughout the documentation is listed in the References section; please remember to cite the appropriate works if you use them.\n\nThis welcome section begins with an introduction to the Input data for RecurrenceMicrostatesAnalysis.jl. Understanding the data types used by the package and their intended purposes is essential before proceeding with the rest of the documentation. We also describe the Output data from RecurrenceMicrostatesAnalysis.jl, explaining the type of data returned when computing recurrence microstate distributions.\n\nThe Tutorial section explains how to use the package in practice. It starts with a brief introduction to RMA and demonstrates how to compute Distributions using RecurrenceMicrostatesAnalysis.jl. Next, we show how to estimate RQA Quantifiers using RMA and discuss quantifiers defined specifically for RMA. This material constitutes the basic level of the documentation and is sufficient to learn how to effectively use this package.\n\nFor users interested in more advanced topics, the Recurrence Functions section discusses different ways of computing recurrence between two states, while the Shapes and Sampling section explains motif shapes used to extract specific information from a Recurrence Plot.\n\nWe also provide a pipeline for GPU computations, which we recommend reading if you plan to use the GPU backend.\n\nThe documentation includes applied examples, such as:\n\nRMA with Machine Learning\n\nFinally, developers interested in contributing to RecurrenceMicrostatesAnalysis.jl are encouraged to read the RecurrenceMicrostatesAnalysis.jl for Devs section.","category":"section"},{"location":"#Input-data-for-RecurrenceMicrostatesAnalysis.jl","page":"Welcome","title":"Input data for RecurrenceMicrostatesAnalysis.jl","text":"RecurrenceMicrostatesAnalysis.jl accepts three types of input, each associated with a different backend:\n\nStateSpaceSet ‚Äî used for multivariate time series, datasets, or state-space representations. This type is employed when working with Recurrence Plots (RP) or Cross-Recurrence Plots (CRP). For RP and CRP analyses, we strongly recommend using this data type, as the backend is optimized for this context.\nAbstractArray{<: Real} ‚Äî used for spatial data, enabling RMA to be applied within the generalized framework of Spatial Recurrence Plots (SRP) (Marwan et al., 2007). Although a Matrix can be used as a substitute for a StateSpaceSet, this is not recommended, since the AbstractArray backend is heavier and incompatible with some features.\nAbstractGPUVector ‚Äî used for time series analysis with the GPU backend. A better explanation is provided in the GPU and Computing RMA distributions sections.\n\nwarning: Warning\nRMA with SRP is an open research field. We include this functionality in the package for exploratory purposes, but the method is not yet mature enough for production use. Nevertheless, feel free to experiment with it in your research. üòÉ","category":"section"},{"location":"#Output-data-from-RecurrenceMicrostatesAnalysis.jl","page":"Welcome","title":"Output data from RecurrenceMicrostatesAnalysis.jl","text":"When computing the RMA distribution, RecurrenceMicrostatesAnalysis.jl returns a Probabilities structure. This type is provided by ComplexityMeasures.jl, allowing this package to interoperate naturally with its tools and workflows.","category":"section"},{"location":"#RecurrenceMicrostatesAnalysis","page":"Welcome","title":"RecurrenceMicrostatesAnalysis","text":"RecurrenceMicrostatesAnalysis.jl\n\n(Image: Package Downloads) (Image: Publication)\n\nRecurrenceMicrostatesAnalysis.jl is a simple and fast Julia-based package for recurrence microstates analysis. It implements the computation of Recurrence Microstates Analysis (RMA) distributions, specific quantifiers ‚Äî such as disorder ‚Äî and the estimation of typical RQA quantifiers, including determinism and laminarity.\n\nRMA is a subfield of Recurrence Analysis and is a powerful tool for analyzing large time series or large datasets using statistical methods, offering high performance and avoiding memory issues. Although the field is still relatively new, it has shown promising applications, including in Machine Learning.\n\nThe package was redesigned in version 0.4.0 to be compatible with DynamicalSystems ecosystem. We therefore recommend exploring the other packages in this ecosystem ‚Äî especially ComplexityMeasures.jl and RecurrenceAnalysis.jl ‚Äî which can be very useful when working with RMA.\n\nTo install the package, run:\n\nimport Pkg\nPkg.add(\"RecurrenceMicrostatesAnalysis\")\n\nThe package documentation is available online, or you can build it locally by running julia docs/make.jl.\n\n\n\n\n\n","category":"module"},{"location":"#StateSpaceSets.StateSpaceSet","page":"Welcome","title":"StateSpaceSets.StateSpaceSet","text":"StateSpaceSet{D, T, V} <: AbstractVector{V}\n\nA dedicated interface for sets in a state space. It is an ordered container of equally-sized points of length D, with element type T, represented by a vector of type V. Typically V is SVector{D,T} or Vector{T} and the data are always stored internally as Vector{V}. SSSet is an alias for StateSpaceSet.\n\nThe underlying Vector{V} can be obtained by vec(ssset), although this is almost never necessary because StateSpaceSet subtypes AbstractVector and extends its interface. StateSpaceSet also supports almost all sensible vector operations like append!, push!, hcat, eachrow, among others. When iterated over, it iterates over its contained points.\n\nConstruction\n\nConstructing a StateSpaceSet is done in three ways:\n\nBy giving in each individual columns of the state space set as Vector{<:Real}: StateSpaceSet(x, y, z, ...).\nBy giving in a matrix whose rows are the state space points: StateSpaceSet(m).\nBy giving in directly a vector of vectors (state space points): StateSpaceSet(v_of_v).\n\nAll constructors allow for two keywords:\n\ncontainer which sets the type of V (the type of inner vectors). At the moment options are only SVector, MVector, or Vector, and by default SVector is used.\nnames which can be an iterable of length D whose elements are Symbols. This allows assigning a name to each dimension and accessing the dimension by name, see below. names is nothing if not given. Use StateSpaceSet(s; names) to add names to an existing set s.\n\nDescription of indexing\n\nWhen indexed with 1 index, StateSpaceSet behaves exactly like its encapsulated vector. i.e., a vector of vectors (state space points). When indexed with 2 indices it behaves like a matrix where each row is a point.\n\nIn the following let i, j be integers, typeof(X) <: AbstractStateSpaceSet and v1, v2 be <: AbstractVector{Int} (v1, v2 could also be ranges, and for performance benefits make v2 an SVector{Int}).\n\nX[i] == X[i, :] gives the ith point (returns an SVector)\nX[v1] == X[v1, :], returns a StateSpaceSet with the points in those indices.\nX[:, j] gives the jth variable timeseries (or collection), as Vector\nX[v1, v2], X[:, v2] returns a StateSpaceSet with the appropriate entries (first indices being \"time\"/point index, while second being variables)\nX[i, j] value of the jth variable, at the ith timepoint\n\nIn all examples above, j can also be a Symbol, provided that names has been given when creating the state space set. This allows accessing a dimension by name. This is provided as a convenience and it is not an optimized operation, hence recommended to be used primarily with X[:, j::Symbol].\n\nUse Matrix(ssset) or StateSpaceSet(matrix) to convert. It is assumed that each column of the matrix is one variable. If you have various timeseries vectors x, y, z, ... pass them like StateSpaceSet(x, y, z, ...). You can use columns(dataset) to obtain the reverse, i.e. all columns of the dataset in a tuple.\n\n\n\n\n\n","category":"type"},{"location":"#ComplexityMeasures.Probabilities","page":"Welcome","title":"ComplexityMeasures.Probabilities","text":"Probabilities <: Array{<:AbstractFloat, N}\nProbabilities(probs::Array [, outcomes [, dimlabels]]) ‚Üí p\nProbabilities(counts::Counts [, outcomes [, dimlabels]]) ‚Üí p\n\nProbabilities stores an N-dimensional array of probabilities, while ensuring that the array sums to 1 (normalized probability mass). In most cases the array is a standard vector. p itself can be manipulated and iterated over, just like its stored array.\n\nThe probabilities correspond to outcomes that describe the axes of the array. If p isa Probabilities, then p.outcomes[i] is an an abstract vector containing the outcomes along the i-th dimension. The outcomes have the same ordering as the probabilities, so that p[i][j] is the probability for outcome p.outcomes[i][j]. The dimensions of the array are named, and can be accessed by p.dimlabels, where p.dimlabels[i] is the label of the i-th dimension. Both outcomes and dimlabels are assigned automatically if not given. If the input is a set of Counts, and outcomes and dimlabels are not given, then the labels and outcomes are inherited from the counts.\n\nExamples\n\njulia> probs = [0.2, 0.2, 0.2, 0.2]; Probabilities(probs) # will be normalized to sum to 1\n Probabilities{Float64,1} over 4 outcomes\n Outcome(1)  0.25\n Outcome(2)  0.25\n Outcome(3)  0.25\n Outcome(4)  0.25\n\njulia> c = Counts([12, 16, 12], [\"out1\", \"out2\", \"out3\"]); Probabilities(c)\n Probabilities{Float64,1} over 3 outcomes\n \"out1\"  0.3\n \"out2\"  0.4\n \"out3\"  0.3\n\n\n\n\n\n","category":"type"},{"location":"#ComplexityMeasures.Counts","page":"Welcome","title":"ComplexityMeasures.Counts","text":"Counts <: Array{<:Integer, N}\nCounts(counts [, outcomes [, dimlabels]]) ‚Üí c\n\nCounts stores an N-dimensional array of integer counts corresponding to a set of outcomes. This is typically called a \"frequency table\" or \"contingency table\".\n\nIf c isa Counts, then c.outcomes[i] is an abstract vector containing the outcomes along the i-th dimension, where c[i][j] is the count corresponding to the outcome c.outcomes[i][j], and c.dimlabels[i] is the label of the i-th dimension. Both labels and outcomes are assigned automatically if not given. c itself can be manipulated and iterated over like its stored array.\n\n\n\n\n\n","category":"type"},{"location":"refs/#References","page":"References","title":"References","text":"Corso,¬†G.; Lima Prado,¬†T.; Santos Lima,¬†G.¬†Z.; Kurths,¬†J. and Lopes,¬†S.¬†R. (2018). Quantifying entropy using recurrence matrix microstates. Chaos 28.\n\n\n\nda¬†Cruz,¬†F.¬†E.; Prado,¬†T.¬†d.; Lopes,¬†S.¬†R.; Marwan,¬†N. and Kurths,¬†J. (2025). Density-based recurrence measures from microstates. Phys.¬†Rev.¬†E 111, 044212.\n\n\n\nEckmann,¬†J.-P.; Kamphorst,¬†S.¬†O. and Ruelle,¬†D. (1987). Recurrence Plots of Dynamical Systems. EUROPHYSICS¬†LETTERS¬†Europhys.¬†Lett 4, 973.\n\n\n\nFerreira,¬†G.¬†V.; Cruz,¬†F.¬†E.; Marghoti,¬†G.; Lima Prado,¬†T.; Lopes,¬†S.¬†R.; Marwan,¬†N. and Kurths,¬†J. (2025). RecurrenceMicrostatesAnalysis.jl: A Julia library for analyzing dynamical systems with recurrence microstates. Chaos 35.\n\n\n\nFlauzino,¬†J.¬†V.; Prado,¬†T.¬†L.; Marwan,¬†N.; Kurths,¬†J. and Lopes,¬†S.¬†R. (2025). Quantifying Disorder in Data. Physical¬†Review¬†Letters 135, 097401.\n\n\n\nHirata,¬†Y. (2021). Recurrence plots for characterizing random dynamical systems. Communications¬†in¬†Nonlinear¬†Science¬†and¬†Numerical¬†Simulation 94.\n\n\n\nIwanski,¬†J.¬†S. and Bradley,¬†E. (1998). Recurrence plots of experimental data: To embed or not to embed? Chaos 8, 861‚Äì871.\n\n\n\nLima Prado,¬†T.; Machado,¬†V.¬†S.; Corso,¬†G.; Santos Lima,¬†G.¬†Z. and Lopes,¬†S.¬†R. (2023). How to compute suitable vicinity parameter and sampling time of recurrence analysis. Nonlinear¬†Dyn. 112, 1141‚Äì1152.\n\n\n\nMarwan,¬†N.; Kurths,¬†J. and Saparin,¬†P. (2007). Generalised Recurrence Plot Analysis for Spatial Data. Physics¬†Letters¬†A 360, 545‚Äì551.\n\n\n\nSpezzatto,¬†G.¬†S.; Flauzino,¬†J.¬†V.; Corso,¬†G.; Boaretto,¬†B.¬†R.; Macau,¬†E.¬†E.; Prado,¬†T.¬†L. and Lopes,¬†S.¬†R. (2024). Recurrence microstates for machine learning classification. Chaos 34.\n\n\n\nWebber,¬†C.¬†L. and Marwan,¬†N. (2015). Recurrence Quantification Analysis: Theory and Best Practices (Springer, Cham, Switzerland).\n\n\n\n","category":"section"},{"location":"tutorial/distributions/#Distributions","page":"Distributions","title":"Distributions","text":"This section introduces the computation of Recurrence Microstates Analysis (RMA) distributions using RecurrenceMicrostatesAnalysis.jl.\n\nWe begin with a Quick start with RecurrenceMicrostatesAnalysis.jl, which demonstrates a simple application example. Next, we present A brief review of Recurrence Plots (RP) and RMA. Finally, we explain the distribution function in Computing RMA distributions, including the role of Histograms.","category":"section"},{"location":"tutorial/distributions/#Quick-start-with-RecurrenceMicrostatesAnalysis.jl","page":"Distributions","title":"Quick start with RecurrenceMicrostatesAnalysis.jl","text":"This section presents concise examples illustrating how to use the package. RMA distributions are computed using the distribution function, which returns a Probabilities structure containing the microstate distribution.\n\nWe start with a simple example based on a uniform random process. First, we generate the data and convert it into a StateSpaceSet:\n\nusing Distributions, RecurrenceMicrostatesAnalysis\ndata = rand(Uniform(0, 1), 10_000);\nssset = StateSpaceSet(data)\n\nNext, we compute the RMA distribution. This requires specifying the recurrence threshold varepsilon and the microstate size N. These parameters are discussed in more detail in A brief review and Optimizing a parameter.\n\nŒµ = 0.27\nN = 2\ndist = distribution(ssset, Œµ, N)\n\nAs another example, we use DynamicalSystems.jl to generate data from the H√©non map, following the example presented in its documentation:\n\nusing DynamicalSystems\n\nfunction henon_rule(u, p, n) # here `n` is \"time\", but we don't use it.\n    x, y = u # system state\n    a, b = p # system parameters\n    xn = 1.0 - a*x^2 + y\n    yn = b*x\n    return SVector(xn, yn)\nend\n\nu0 = [0.2, 0.3]\np0 = [1.4, 0.3]\n\nhenon = DeterministicIteratedMap(henon_rule, u0, p0)\n\ntotal_time = 10_000\nX, t = trajectory(henon, total_time)\nX\n\nFinally, we compute the RMA distribution of the trajectory X. Here, the threshold is selected using optimize by maximizing the recurrence microstate entropy:\n\nŒµ, S = optimize(Threshold(), RecurrenceEntropy(), X, N)\n\ndist = distribution(X, Œµ, N)","category":"section"},{"location":"tutorial/distributions/#A-brief-review","page":"Distributions","title":"A brief review","text":"Recurrence Plots (RPs) were introduced in 1987 by Eckmann et al. (Eckmann et al., 1987) as a method for analyzing dynamical systems through recurrence properties.\n\nConsider a time series vecx_i in mathbbR^d, i in 1 2 dots K, where K is the length of the time series and d is the dimension of the phase space. The recurrence plot is defined by the recurrence matrix\n\nR_ij = Theta(varepsilon - vec x_i - vec x_j)\n\nwhere Theta(cdot) denotes the Heaviside step function and varepsilon is the recurrence threshold.\n\nThe following figure shows examples of recurrence plots for different systems: (a) white noise; (b) a superposition of harmonic oscillators; (c) a logistic map with a linear trend; (d) Brownian motion.\n\n(Image: Image of four RPs with their timeseries)\n\nA recurrence microstate is a local structure extracted from an RP. For a given microstate shape and size, the set of possible microstates is finite. For example, square microstates with size N = 2 yield 16 distinct configurations.\n\n(Image: Image of the 16 squared microstates to N = 2)\n\nRecurrence Microstates Analysis (RMA) uses the probability distribution of these microstates as a source of information for characterizing dynamical systems.","category":"section"},{"location":"tutorial/distributions/#Computing-RMA-distributions","page":"Distributions","title":"Computing RMA distributions","text":"The computation of RMA distributions is the core functionality of RecurrenceMicrostatesAnalysis.jl. All other tools in the package rely on these distributions as their primary source of information.\n\nRMA distributions are computed using the distribution function:\n\nA commonly used convenience interface is:\n\ndistribution([x], Œµ::Float, n::Int; kwargs...)\n\nThis method automatically selects a CPUCore when x is a StateSpaceSet and a GPUCore when x is an AbstractGPUVector. By default, square microstates of size n are used.\n\nAdditional keyword arguments include:\n\nrate::Float64: Sampling rate (default: 0.05).\nsampling::SamplingMode: Sampling mode (default: SRandom).\nmetric::Metric: Distance metric from Distances.jl. When using a GPUCore, a GPUMetric must be provided.\n\nwarning: Warning\nGPU backends require inputs of type Float32. Float64 inputs are not supported on GPU.\n\nAlternatively, a RecurrenceExpression can be specified directly:\n\ndistribution([x], expr::RecurrenceExpression, n::Int; kwargs...)\n\nExample:\n\nexpr = Corridor(0.05, 0.27)\ndist = distribution(ssset, expr, 2)\n\nIf a custom MicrostateShape is required, the call simplifies to:\n\ndistribution([x], shape::MicrostateShape; kwargs...)\n\nExample:\n\nshape = Triangle(Standard(0.27), 3)\ndist = distribution(ssset, shape)\n\n","category":"section"},{"location":"tutorial/distributions/#Cross-recurrence-plots","page":"Distributions","title":"Cross-recurrence plots","text":"RMA distributions can also be computed from Cross-Recurrence Plots (CRPs) by providing two time series:\n\ndistribution([x], [y], expr::RecurrenceExpression, n::Int; kwargs...)\ndistribution([x], [y], shape::MicrostateShape; kwargs...)\n\nExample:\n\ndata_1 = StateSpaceSet(rand(Uniform(0, 1), 1000))\ndata_2 = StateSpaceSet(rand(Uniform(0, 1), 2000))\ndist = distribution(data_1, data_2, 0.27, 2)\n\ndanger: Danger\nThe inputs x and y must have the same phase-space dimensionality. The following example is invalid and will raise an exception:data_1 = StateSpaceSet(rand(Uniform(0, 1), (1000, 2)))\ndata_2 = StateSpaceSet(rand(Uniform(0, 1), (2000, 3)))\ndist = distribution(data_1, data_2, 0.27, 2)\n\n","category":"section"},{"location":"tutorial/distributions/#Spatial-data","page":"Distributions","title":"Spatial data","text":"The package also provides experimental support for spatial data, following \"Generalised Recurrence Plot Analysis for Spatial Data\" (Marwan et al., 2007). In this context, input data are provided as AbstractArrays:\n\n    vecx_vec i in mathbbR^mquad veci in mathbbZ^d\n\nFor example:\n\nspatialdata = rand(Uniform(0, 1), (2, 50, 50))\n\nDue to the high dimensionality of spatial recurrence plots, direct visualization is often infeasible. RMA distributions provide a compact alternative by sampling microstates directly from the data.\n\nExamples:\n\nFull 2 times d microstates:\n\ndistribution(spatialdata, Rect(Standard(0.27), (2, 2, 2, 2)))\n\nspatialdata_1 = rand(Uniform(0, 1), (2, 50, 50))\nspatialdata_2 = rand(Uniform(0, 1), (2, 25, 25))\ndistribution(spatialdata_1, spatialdata_2, Rect(Standard(0.27), (2, 2, 2, 2)))\n\nProjected microstates:\n\ndistribution(spatialdata, Rect(Standard(0.27), (2, 1, 2, 1)))\n\ndistribution(spatialdata_1, spatialdata_2, Rect(Standard(0.27), (2, 1, 2, 1)))","category":"section"},{"location":"tutorial/distributions/#Histograms","page":"Distributions","title":"Histograms","text":"The histogram function counts the occurrences of each microstate identified during sampling. It is called internally by distribution , which converts the resulting Counts into Probabilities.","category":"section"},{"location":"tutorial/distributions/#RecurrenceMicrostatesAnalysis.distribution","page":"Distributions","title":"RecurrenceMicrostatesAnalysis.distribution","text":"distribution(core::RMACore, [x], [y])\n\nCompute an RMA distribution from the recurrence structure constructed using the input data [x] and [y].\n\nIf [x] and [y] are identical, the result corresponds to a Recurrence Plot (RP); otherwise, it corresponds to a Cross-Recurrence Plot (CRP).\n\nThe core argument must be a subtype of RMACore and defines how the computation is performed, including the execution backend (CPU or GPU), the microstate shape, the recurrence expression, and the sampling mode.\n\nThe result is returned as a Probabilities object, where each index corresponds to the decimal representation of the associated microstate.\n\nInternally, distribution calls histogram and converts the resulting counts into probabilities.\n\n\n\n\n\ndistribution(core::CPUCore, [x], [y]; kwargs...)\n\nCompute an RMA distribution for the input data [x] and [y] using a CPU backend configuration defined by core, which must be a CPUCore.\n\nFor time-series analysis, the inputs [x] and [y] must be provided as StateSpaceSet objects. For spatial analysis, the inputs must be provided as AbstractArrays.\n\nArguments\n\ncore: A CPUCore defining the MicrostateShape, RecurrenceExpression, and SamplingMode used in the computation.\n[x]: Input data provided as a StateSpaceSet or an AbstractArray.\n[y]: Input data provided as a StateSpaceSet or an AbstractArray.\n\nKeyword Arguments\n\nthreads: Number of threads used to compute the distribution. By default, this is set to Threads.nthreads(), which can be specified at Julia startup using --threads N or via the JULIA_NUM_THREADS environment variable.\n\nExamples\n\nTime series:\n\nssset = StateSpaceSet(rand(Float64, (1000)))\ncore = CPUCore(Rect(Standard(0.27), 2), SRandom(0.05))\ndist = distribution(core, ssset, ssset)\n\nSpatial data:\n\nspatialdata = rand(Float64, (3, 50, 50))\ncore = CPUCore(Rect(Standard(0.5), (2, 2, 1, 1)), SRandom(0.05))\ndist = distribution(core, spatialdata, spatialdata)\n\n\n\n\n\ndistribution(core::GPUCore, [x], [y]; kwargs...)\n\nCompute an RMA distribution for the input data [x] and [y] using a GPU backend configuration defined by core, which must be a GPUCore.\n\nThe inputs [x] and [y] must be vectors of type AbstractGPUVector. This method supports time-series analysis only.\n\nnote: Note\nThe resulting distribution is copied from GPU memory back to the CPU.\n\nArguments\n\ncore: A GPUCore defining the MicrostateShape, RecurrenceExpression, and SamplingMode used in the computation.\n[x]: Input data provided as an AbstractGPUVector.\n[y]: Input data provided as an AbstractGPUVector.\n\nKeyword Arguments\n\ngroupsize: Number of threads per GPU workgroup.\n\nExamples\n\nusing CUDA\ngpudata = StateSpaceSet(Float32.(data)) |> CuVector\ncore = GPUCore(CUDABackend(), Rect(Standard(0.27f0; metric = GPUEuclidean()), 2), SRandom(0.05))\ndist = distribution(core, gpudata, gpudata)\n\nwarning: Warning\nSpatial data are not supported by GPUCore.\n\n\n\n\n\n","category":"function"},{"location":"tutorial/distributions/#RecurrenceMicrostatesAnalysis.histogram","page":"Distributions","title":"RecurrenceMicrostatesAnalysis.histogram","text":"histogram(core::RMACore, [x], [y])\n\nCompute the histogram of recurrence microstates for the input data [x] and [y] using the specified backend core, which must be an RMACore.\n\nThis function executes the full backend pipeline: sampling the recurrence space, constructing microstates, and evaluating recurrences.\n\nThe result is returned as a Counts object, where each index corresponds to the decimal representation of the associated microstate.\n\n\n\n\n\nhistogram(core::StandardCPUCore, [x], [y]; kwargs...)\n\nCompute the histogram of recurrence microstates for an abstract recurrence structure constructed from the input data [x] and [y].\n\nIf [x] and [y] are identical, the result corresponds to a Recurrence Plot (RP); otherwise, it corresponds to a Cross-Recurrence Plot (CRP).\n\nThe result is returned as a Counts object representing the histogram of recurrence microstates for the given input data.\n\nThis method implements the CPU backend using a CPUCore, specifically the StandardCPUCore implementation.\n\nArguments\n\ncore: A StandardCPUCore defining the CPU backend configuration.\n[x]: Input data provided as a StateSpaceSet or an AbstractArray.\n[y]: Input data provided as a StateSpaceSet or an AbstractArray.\n\nnote: Note\nStateSpaceSet and AbstractArray inputs use different internal backends and therefore different histogram implementations. Both interfaces share the same method signature, differing only in the input data representation.\n\nKeyword Arguments\n\nthreads: Number of threads used to compute the histogram. By default, this is set to Threads.nthreads(), which can be specified at Julia startup using --threads N or via the JULIA_NUM_THREADS environment variable.\n\nExamples\n\nTime series:\n\nssset = StateSpaceSet(rand(Float64, (1000)))\ncore = CPUCore(Rect(Standard(0.27), 2), SRandom(0.05))\ndist = histogram(core, ssset, ssset)\n\nSpatial data:\n\nspatialdata = rand(Float64, (3, 50, 50))\ncore = CPUCore(Rect(Standard(0.5), (2, 2, 1, 1)), SRandom(0.05))\ndist = histogram(core, spatialdata, spatialdata)\n\n\n\n\n\nhistogram(core::StandardGPUCore, [x], [y]; kwargs...)\n\nCompute the histogram of recurrence microstates for an abstract recurrence structure constructed from the input data [x] and [y].\n\nIf [x] and [y] are identical, the result corresponds to a Recurrence Plot (RP); otherwise, it corresponds to a Cross-Recurrence Plot (CRP).\n\nThe result is returned as a Counts object representing the histogram of recurrence microstates for the given input data.\n\nnote: Note\nThe resulting histogram is copied from GPU memory back to the CPU.\n\nThis method implements the GPU backend using a GPUCore, specifically the StandardGPUCore implementation.\n\nArguments\n\ncore: A StandardGPUCore defining the GPU backend configuration.\n[x]: Input data provided as an AbstractGPUVector.\n[y]: Input data provided as an AbstractGPUVector.\n\nKeyword Arguments\n\ngroupsize: Number of threads per GPU workgroup.\n\nExamples\n\nusing CUDA\ngpudata = StateSpaceSet(Float32.(data)) |> CuVector\ncore = GPUCore(CUDABackend(), Rect(Standard(0.27f0; metric = GPUEuclidean()), 2), SRandom(0.05))\ndist = histogram(core, gpudata, gpudata)\n\n\n\n\n\n","category":"function"}]
}
